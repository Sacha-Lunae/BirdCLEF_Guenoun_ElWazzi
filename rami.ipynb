{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comprendre la donn√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('./birdclef-2024/train_metadata.csv')\n",
    "df_birbs = pd.read_csv('./birdclef-2024/eBird_Taxonomy_v2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001F73B834F90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.groupby('primary_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary_label\n",
      "zitcis1    500\n",
      "lirplo     500\n",
      "litgre1    500\n",
      "comgre     500\n",
      "comkin1    500\n",
      "          ... \n",
      "blaeag1      6\n",
      "wynlau1      6\n",
      "niwpig1      5\n",
      "asiope1      5\n",
      "integr       5\n",
      "Name: count, Length: 182, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# show unique primary labels\n",
    "# print(df_meta['primary_label'].unique())\n",
    "\n",
    "# for each primary label, show the number of samples\n",
    "print(df_meta['primary_label'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary labels are in the form of a list of strings, so we need to split them into separate columns to count them\n",
    "df_meta['secondary_labels'] = df_meta['secondary_labels'].str.split('|')\n",
    "df_meta = df_meta.explode('secondary_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['primary_label', 'secondary_labels', 'type', 'latitude', 'longitude',\n",
       "       'scientific_name', 'common_name', 'author', 'license', 'rating', 'url',\n",
       "       'filename'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_audio(file_path, sr=22050):\n",
    "    audio, sr = librosa.load(file_path, sr=sr)\n",
    "    return audio, sr\n",
    "\n",
    "def get_spectrogram(audio, sr=22050, n_mels=128, fmax=8000):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    return spectrogram\n",
    "\n",
    "def spectral_gate(spec, noise_mean, threshold):\n",
    "    spec_denoised = spec - noise_mean[:, np.newaxis] * threshold\n",
    "    spec_denoised[spec_denoised < 0] = 0\n",
    "    return spec_denoised\n",
    "\n",
    "def apply_augmentation(spec):\n",
    "    noise = np.random.randn(*spec.shape) * 0.01\n",
    "    spec_noise_aug = spec + noise\n",
    "    spec_distort1 = spec * (1 + 0.1 * np.sin(2 * np.pi * np.arange(spec.shape[1]) / 50))\n",
    "    spec_distort2 = spec * (1 + 0.1 * np.cos(2 * np.pi * np.arange(spec.shape[1]) / 50))\n",
    "    return spec_noise_aug, spec_distort1, spec_distort2\n",
    "\n",
    "def generate_spectrogram(row, audio_len=22050*5, n_mels=128, fmax=8000):\n",
    "    audio, sr = load_audio(row['file_path'])\n",
    "    audio = audio[:audio_len]\n",
    "    spec = get_spectrogram(audio, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "    return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdSpeciesClassifier:\n",
    "    def __init__(self, metadata_path, audio_dir, num_classes, input_shape=(128, 128, 1), batch_size=32, epochs=10):\n",
    "        self.metadata_path = metadata_path\n",
    "        self.audio_dir = audio_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.meta_columns = ['latitude', 'longitude']  # Define meta_columns here\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        # Image input branch\n",
    "        img_input = Input(shape=self.input_shape, name='img_input')\n",
    "        x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        # Metadata input branch\n",
    "        meta_input = Input(shape=(len(self.meta_columns),), name='meta_input')\n",
    "        y = Dense(128, activation='relu')(meta_input)\n",
    "        y = Dropout(0.5)(y)\n",
    "        \n",
    "        # Concatenate the outputs\n",
    "        combined = concatenate([x, y])\n",
    "        z = Dense(128, activation='relu')(combined)\n",
    "        z = Dropout(0.5)(z)\n",
    "        z = Dense(self.num_classes, activation='softmax')(z)\n",
    "        \n",
    "        model = Model(inputs=[img_input, meta_input], outputs=z)\n",
    "        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def preprocess_metadata(self, df):\n",
    "        meta_data = df[self.meta_columns].values\n",
    "        labels = df['primary_label'].astype('category').cat.codes\n",
    "        labels = to_categorical(labels, num_classes=self.num_classes)\n",
    "        return meta_data, labels\n",
    "    \n",
    "    def spectrogram_generator(self, df):\n",
    "        num_samples = len(df)\n",
    "        while True:\n",
    "            df = df.sample(frac=1).reset_index(drop=True)\n",
    "            for offset in range(0, num_samples, self.batch_size):\n",
    "                batch_df = df.iloc[offset:offset+self.batch_size]\n",
    "                batch_spectrograms = []\n",
    "                batch_meta_data = []\n",
    "                batch_labels = []\n",
    "                for _, row in batch_df.iterrows():\n",
    "                    spec = generate_spectrogram(row)\n",
    "                    batch_spectrograms.append(spec)\n",
    "                    batch_meta_data.append(row[self.meta_columns])\n",
    "                    batch_labels.append(row['primary_label'])\n",
    "                \n",
    "                X_img = np.array(batch_spectrograms)[..., np.newaxis]\n",
    "                X_meta = np.array(batch_meta_data)\n",
    "                y = to_categorical(np.array(batch_labels).astype('category').cat.codes, num_classes=self.num_classes)\n",
    "                \n",
    "                yield {'img_input': X_img, 'meta_input': X_meta}, y\n",
    "    \n",
    "    def train(self):\n",
    "        df = pd.read_csv(self.metadata_path)\n",
    "        train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        train_meta, train_labels = self.preprocess_metadata(train_df)\n",
    "        val_meta, val_labels = self.preprocess_metadata(val_df)\n",
    "        \n",
    "        steps_per_epoch = len(train_df) // self.batch_size\n",
    "        validation_steps = len(val_df) // self.batch_size\n",
    "        \n",
    "        self.model.fit(\n",
    "            self.spectrogram_generator(train_df),\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=self.spectrogram_generator(val_df),\n",
    "            validation_steps=validation_steps,\n",
    "            epochs=self.epochs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CFG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming 'num_classes' is the number of unique bird species\u001b[39;00m\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m BirdSpeciesClassifier(\n\u001b[0;32m      3\u001b[0m     metadata_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./birdclef-2024/train_metadata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     audio_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./birdclef-2024/train_audio/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 77\u001b[0m, in \u001b[0;36mBirdSpeciesClassifier.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_df) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m     75\u001b[0m validation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_df) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectrogram_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectrogram_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[9], line 57\u001b[0m, in \u001b[0;36mBirdSpeciesClassifier.spectrogram_generator\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     55\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m batch_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 57\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     batch_spectrograms\u001b[38;5;241m.\u001b[39mappend(spec)\n\u001b[0;32m     59\u001b[0m     batch_meta_data\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_columns])\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mgenerate_spectrogram\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_spectrogram\u001b[39m(row):\n\u001b[0;32m     22\u001b[0m     audio, sr \u001b[38;5;241m=\u001b[39m load_audio(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbirdclef-2024/train_audio/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39mfilename))\n\u001b[1;32m---> 23\u001b[0m     audio \u001b[38;5;241m=\u001b[39m audio[:\u001b[43mCFG\u001b[49m\u001b[38;5;241m.\u001b[39maudio_len]\n\u001b[0;32m     24\u001b[0m     spec \u001b[38;5;241m=\u001b[39m get_spectrogram(audio)\n\u001b[0;32m     25\u001b[0m     spec_db \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mpower_to_db(spec, ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CFG' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming 'num_classes' is the number of unique bird species\n",
    "classifier = BirdSpeciesClassifier(\n",
    "    metadata_path='./birdclef-2024/train_metadata.csv',\n",
    "    audio_dir='./birdclef-2024/train_audio/',\n",
    "    num_classes=df_meta['primary_label'].nunique(),\n",
    "    input_shape=(128, 128, 1),\n",
    "    batch_size=32,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "classifier.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

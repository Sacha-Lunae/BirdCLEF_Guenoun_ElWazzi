{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"./birdclef-2024/train_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>39.2297</td>\n",
       "      <td>118.1987</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>Matt Slaymaker</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.xeno-canto.org/134896</td>\n",
       "      <td>asbfly/XC134896.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>51.4030</td>\n",
       "      <td>104.6401</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>Magnus Hellström</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>https://www.xeno-canto.org/164848</td>\n",
       "      <td>asbfly/XC164848.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>36.3319</td>\n",
       "      <td>127.3555</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>Stuart Fisher</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>https://www.xeno-canto.org/175797</td>\n",
       "      <td>asbfly/XC175797.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>21.1697</td>\n",
       "      <td>70.6005</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>vir joshi</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.xeno-canto.org/207738</td>\n",
       "      <td>asbfly/XC207738.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asbfly</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>15.5442</td>\n",
       "      <td>73.7733</td>\n",
       "      <td>Muscicapa dauurica</td>\n",
       "      <td>Asian Brown Flycatcher</td>\n",
       "      <td>Albert Lastukhin &amp; Sergei Karpeev</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.xeno-canto.org/209218</td>\n",
       "      <td>asbfly/XC209218.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24454</th>\n",
       "      <td>zitcis1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['']</td>\n",
       "      <td>43.5925</td>\n",
       "      <td>4.5434</td>\n",
       "      <td>Cisticola juncidis</td>\n",
       "      <td>Zitting Cisticola</td>\n",
       "      <td>Chèvremont Fabian</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://xeno-canto.org/845747</td>\n",
       "      <td>zitcis1/XC845747.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24455</th>\n",
       "      <td>zitcis1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['']</td>\n",
       "      <td>43.5925</td>\n",
       "      <td>4.5434</td>\n",
       "      <td>Cisticola juncidis</td>\n",
       "      <td>Zitting Cisticola</td>\n",
       "      <td>Chèvremont Fabian</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://xeno-canto.org/845817</td>\n",
       "      <td>zitcis1/XC845817.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24456</th>\n",
       "      <td>zitcis1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['']</td>\n",
       "      <td>51.1207</td>\n",
       "      <td>4.5607</td>\n",
       "      <td>Cisticola juncidis</td>\n",
       "      <td>Zitting Cisticola</td>\n",
       "      <td>Wim Jacobs</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://xeno-canto.org/856176</td>\n",
       "      <td>zitcis1/XC856176.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24457</th>\n",
       "      <td>zitcis1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['']</td>\n",
       "      <td>41.5607</td>\n",
       "      <td>-8.4236</td>\n",
       "      <td>Cisticola juncidis</td>\n",
       "      <td>Zitting Cisticola</td>\n",
       "      <td>Jorge Leitão</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>https://xeno-canto.org/856723</td>\n",
       "      <td>zitcis1/XC856723.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24458</th>\n",
       "      <td>zitcis1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['']</td>\n",
       "      <td>13.7747</td>\n",
       "      <td>100.8919</td>\n",
       "      <td>Cisticola juncidis</td>\n",
       "      <td>Zitting Cisticola</td>\n",
       "      <td>Sam Hambly</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://xeno-canto.org/858550</td>\n",
       "      <td>zitcis1/XC858550.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24459 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      primary_label secondary_labels      type  latitude  longitude  \\\n",
       "0            asbfly               []  ['call']   39.2297   118.1987   \n",
       "1            asbfly               []  ['song']   51.4030   104.6401   \n",
       "2            asbfly               []  ['song']   36.3319   127.3555   \n",
       "3            asbfly               []  ['call']   21.1697    70.6005   \n",
       "4            asbfly               []  ['call']   15.5442    73.7733   \n",
       "...             ...              ...       ...       ...        ...   \n",
       "24454       zitcis1               []      ['']   43.5925     4.5434   \n",
       "24455       zitcis1               []      ['']   43.5925     4.5434   \n",
       "24456       zitcis1               []      ['']   51.1207     4.5607   \n",
       "24457       zitcis1               []      ['']   41.5607    -8.4236   \n",
       "24458       zitcis1               []      ['']   13.7747   100.8919   \n",
       "\n",
       "          scientific_name             common_name  \\\n",
       "0      Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "1      Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "2      Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "3      Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "4      Muscicapa dauurica  Asian Brown Flycatcher   \n",
       "...                   ...                     ...   \n",
       "24454  Cisticola juncidis       Zitting Cisticola   \n",
       "24455  Cisticola juncidis       Zitting Cisticola   \n",
       "24456  Cisticola juncidis       Zitting Cisticola   \n",
       "24457  Cisticola juncidis       Zitting Cisticola   \n",
       "24458  Cisticola juncidis       Zitting Cisticola   \n",
       "\n",
       "                                  author  \\\n",
       "0                         Matt Slaymaker   \n",
       "1                       Magnus Hellström   \n",
       "2                          Stuart Fisher   \n",
       "3                              vir joshi   \n",
       "4      Albert Lastukhin & Sergei Karpeev   \n",
       "...                                  ...   \n",
       "24454                  Chèvremont Fabian   \n",
       "24455                  Chèvremont Fabian   \n",
       "24456                         Wim Jacobs   \n",
       "24457                       Jorge Leitão   \n",
       "24458                         Sam Hambly   \n",
       "\n",
       "                                                 license  rating  \\\n",
       "0      Creative Commons Attribution-NonCommercial-Sha...     5.0   \n",
       "1      Creative Commons Attribution-NonCommercial-Sha...     2.5   \n",
       "2      Creative Commons Attribution-NonCommercial-Sha...     2.5   \n",
       "3      Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "4      Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "...                                                  ...     ...   \n",
       "24454  Creative Commons Attribution-NonCommercial-Sha...     5.0   \n",
       "24455  Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "24456  Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "24457  Creative Commons Attribution-NonCommercial-Sha...     4.5   \n",
       "24458  Creative Commons Attribution-NonCommercial-Sha...     5.0   \n",
       "\n",
       "                                     url              filename  \n",
       "0      https://www.xeno-canto.org/134896   asbfly/XC134896.ogg  \n",
       "1      https://www.xeno-canto.org/164848   asbfly/XC164848.ogg  \n",
       "2      https://www.xeno-canto.org/175797   asbfly/XC175797.ogg  \n",
       "3      https://www.xeno-canto.org/207738   asbfly/XC207738.ogg  \n",
       "4      https://www.xeno-canto.org/209218   asbfly/XC209218.ogg  \n",
       "...                                  ...                   ...  \n",
       "24454      https://xeno-canto.org/845747  zitcis1/XC845747.ogg  \n",
       "24455      https://xeno-canto.org/845817  zitcis1/XC845817.ogg  \n",
       "24456      https://xeno-canto.org/856176  zitcis1/XC856176.ogg  \n",
       "24457      https://xeno-canto.org/856723  zitcis1/XC856723.ogg  \n",
       "24458      https://xeno-canto.org/858550  zitcis1/XC858550.ogg  \n",
       "\n",
       "[24459 rows x 12 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_meta[[\"primary_label\", \"filename\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features_with_path(args):\n",
    "    ogg_file_path, max_length = args\n",
    "    return extract_audio_features(ogg_file_path, max_length)\n",
    "\n",
    "def extract_audio_features(ogg_file_path, max_length=22050*5):\n",
    "    y, sr = librosa.load(ogg_file_path, sr=None)\n",
    "    \n",
    "    # Ensure the audio is of fixed length\n",
    "    if len(y) < max_length:\n",
    "        y = np.pad(y, (0, max_length - len(y)), 'constant')\n",
    "    else:\n",
    "        y = y[:max_length]\n",
    "    \n",
    "    # Extract features\n",
    "    features = {}\n",
    "\n",
    "    # Mel spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    features['mel_spectrogram'] = S_dB\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    features['mfcc'] = mfcc\n",
    "\n",
    "    # Chroma feature\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features['chroma'] = chroma\n",
    "\n",
    "    # Spectral contrast\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    features['spectral_contrast'] = spectral_contrast\n",
    "\n",
    "    # Tonnetz\n",
    "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)\n",
    "    features['tonnetz'] = tonnetz\n",
    "\n",
    "    # Spectral centroid\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    features['spectral_centroid'] = spectral_centroid\n",
    "\n",
    "    # Spectral bandwidth\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    features['spectral_bandwidth'] = spectral_bandwidth\n",
    "\n",
    "    # Spectral rolloff\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    features['spectral_rolloff'] = spectral_rolloff\n",
    "\n",
    "    # Zero crossing rate\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "    features['zero_crossing_rate'] = zero_crossing_rate\n",
    "\n",
    "    # RMS\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    features['rms'] = rms\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: mel_spectrogram\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-71.131088</td>\n",
       "      <td>-64.629059</td>\n",
       "      <td>-64.798882</td>\n",
       "      <td>-65.517334</td>\n",
       "      <td>-64.943108</td>\n",
       "      <td>-66.595901</td>\n",
       "      <td>...</td>\n",
       "      <td>-68.542099</td>\n",
       "      <td>-62.939053</td>\n",
       "      <td>-61.753540</td>\n",
       "      <td>-64.483032</td>\n",
       "      <td>-63.943794</td>\n",
       "      <td>-68.828384</td>\n",
       "      <td>-75.564575</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-69.745300</td>\n",
       "      <td>-58.308228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-78.152901</td>\n",
       "      <td>-77.862320</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.897995</td>\n",
       "      <td>-64.690155</td>\n",
       "      <td>-63.297081</td>\n",
       "      <td>-61.861908</td>\n",
       "      <td>-62.233330</td>\n",
       "      <td>-65.241440</td>\n",
       "      <td>-66.423111</td>\n",
       "      <td>-74.839699</td>\n",
       "      <td>-68.645683</td>\n",
       "      <td>-57.374542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.738266</td>\n",
       "      <td>-63.308044</td>\n",
       "      <td>-63.542503</td>\n",
       "      <td>-68.342384</td>\n",
       "      <td>-66.267365</td>\n",
       "      <td>-65.165871</td>\n",
       "      <td>-68.677277</td>\n",
       "      <td>-73.797104</td>\n",
       "      <td>-69.288116</td>\n",
       "      <td>-58.136024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-78.352684</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-79.861069</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.366867</td>\n",
       "      <td>-71.845642</td>\n",
       "      <td>-70.448776</td>\n",
       "      <td>-73.537903</td>\n",
       "      <td>-71.473465</td>\n",
       "      <td>-71.168381</td>\n",
       "      <td>-72.104736</td>\n",
       "      <td>-69.305649</td>\n",
       "      <td>-67.361259</td>\n",
       "      <td>-57.354889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.917900</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-76.070633</td>\n",
       "      <td>-72.207756</td>\n",
       "      <td>-73.334656</td>\n",
       "      <td>-75.337105</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-70.599350</td>\n",
       "      <td>-68.497894</td>\n",
       "      <td>-58.325111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3          4          5          6          7    \\\n",
       "0 -80.0 -80.0 -80.0 -80.0 -71.131088 -64.629059 -64.798882 -65.517334   \n",
       "1 -80.0 -80.0 -80.0 -80.0 -78.152901 -77.862320 -80.000000 -80.000000   \n",
       "2 -80.0 -80.0 -80.0 -80.0 -80.000000 -80.000000 -80.000000 -80.000000   \n",
       "3 -80.0 -80.0 -80.0 -80.0 -78.352684 -80.000000 -80.000000 -80.000000   \n",
       "4 -80.0 -80.0 -80.0 -80.0 -80.000000 -80.000000 -80.000000 -80.000000   \n",
       "\n",
       "         8          9    ...        206        207        208        209  \\\n",
       "0 -64.943108 -66.595901  ... -68.542099 -62.939053 -61.753540 -64.483032   \n",
       "1 -80.000000 -80.000000  ... -66.897995 -64.690155 -63.297081 -61.861908   \n",
       "2 -80.000000 -80.000000  ... -61.738266 -63.308044 -63.542503 -68.342384   \n",
       "3 -80.000000 -79.861069  ... -64.366867 -71.845642 -70.448776 -73.537903   \n",
       "4 -80.000000 -80.000000  ... -73.917900 -80.000000 -76.070633 -72.207756   \n",
       "\n",
       "         210        211        212        213        214        215  \n",
       "0 -63.943794 -68.828384 -75.564575 -80.000000 -69.745300 -58.308228  \n",
       "1 -62.233330 -65.241440 -66.423111 -74.839699 -68.645683 -57.374542  \n",
       "2 -66.267365 -65.165871 -68.677277 -73.797104 -69.288116 -58.136024  \n",
       "3 -71.473465 -71.168381 -72.104736 -69.305649 -67.361259 -57.354889  \n",
       "4 -73.334656 -75.337105 -80.000000 -70.599350 -68.497894 -58.325111  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: mfcc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-695.373413</td>\n",
       "      <td>-695.373413</td>\n",
       "      <td>-695.354370</td>\n",
       "      <td>-680.230347</td>\n",
       "      <td>-643.505615</td>\n",
       "      <td>-619.225769</td>\n",
       "      <td>-591.797607</td>\n",
       "      <td>-570.970276</td>\n",
       "      <td>-563.205383</td>\n",
       "      <td>-558.302429</td>\n",
       "      <td>...</td>\n",
       "      <td>-306.195435</td>\n",
       "      <td>-323.671509</td>\n",
       "      <td>-334.408813</td>\n",
       "      <td>-339.167542</td>\n",
       "      <td>-338.049377</td>\n",
       "      <td>-331.991302</td>\n",
       "      <td>-328.520233</td>\n",
       "      <td>-321.373627</td>\n",
       "      <td>-314.663361</td>\n",
       "      <td>-300.228394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>-1.203629</td>\n",
       "      <td>-5.267553</td>\n",
       "      <td>-6.745506</td>\n",
       "      <td>-6.516578</td>\n",
       "      <td>-5.824792</td>\n",
       "      <td>-6.088688</td>\n",
       "      <td>-6.661309</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.372093</td>\n",
       "      <td>-18.021332</td>\n",
       "      <td>-13.957712</td>\n",
       "      <td>-14.097721</td>\n",
       "      <td>-14.342066</td>\n",
       "      <td>-13.824280</td>\n",
       "      <td>-19.953529</td>\n",
       "      <td>-27.281433</td>\n",
       "      <td>-24.620096</td>\n",
       "      <td>-22.640423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.026895</td>\n",
       "      <td>-17.487480</td>\n",
       "      <td>-48.594494</td>\n",
       "      <td>-65.481293</td>\n",
       "      <td>-84.124863</td>\n",
       "      <td>-95.908485</td>\n",
       "      <td>-98.228455</td>\n",
       "      <td>-101.852127</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.743835</td>\n",
       "      <td>-175.672638</td>\n",
       "      <td>-179.184937</td>\n",
       "      <td>-179.671829</td>\n",
       "      <td>-181.474518</td>\n",
       "      <td>-182.583771</td>\n",
       "      <td>-186.912994</td>\n",
       "      <td>-188.352554</td>\n",
       "      <td>-176.718735</td>\n",
       "      <td>-133.417740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>2.805940</td>\n",
       "      <td>12.572548</td>\n",
       "      <td>14.241904</td>\n",
       "      <td>11.571680</td>\n",
       "      <td>11.357303</td>\n",
       "      <td>12.281723</td>\n",
       "      <td>13.987467</td>\n",
       "      <td>...</td>\n",
       "      <td>65.480469</td>\n",
       "      <td>54.011528</td>\n",
       "      <td>45.415066</td>\n",
       "      <td>47.022861</td>\n",
       "      <td>52.940224</td>\n",
       "      <td>50.364700</td>\n",
       "      <td>52.326881</td>\n",
       "      <td>65.002045</td>\n",
       "      <td>67.655022</td>\n",
       "      <td>71.527222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026674</td>\n",
       "      <td>8.966082</td>\n",
       "      <td>11.528910</td>\n",
       "      <td>8.192678</td>\n",
       "      <td>3.498780</td>\n",
       "      <td>-2.270911</td>\n",
       "      <td>-9.443663</td>\n",
       "      <td>-8.712378</td>\n",
       "      <td>...</td>\n",
       "      <td>-91.412827</td>\n",
       "      <td>-79.573364</td>\n",
       "      <td>-68.684639</td>\n",
       "      <td>-62.239941</td>\n",
       "      <td>-48.788322</td>\n",
       "      <td>-53.536591</td>\n",
       "      <td>-59.001015</td>\n",
       "      <td>-60.851425</td>\n",
       "      <td>-54.280022</td>\n",
       "      <td>-25.470638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1           2           3           4           5    \\\n",
       "0 -695.373413 -695.373413 -695.354370 -680.230347 -643.505615 -619.225769   \n",
       "1    0.000000    0.000000    0.000993   -1.203629   -5.267553   -6.745506   \n",
       "2    0.000000    0.000000   -0.026895  -17.487480  -48.594494  -65.481293   \n",
       "3    0.000000    0.000000   -0.002972    2.805940   12.572548   14.241904   \n",
       "4    0.000000    0.000000    0.026674    8.966082   11.528910    8.192678   \n",
       "\n",
       "          6           7           8           9    ...         206  \\\n",
       "0 -591.797607 -570.970276 -563.205383 -558.302429  ... -306.195435   \n",
       "1   -6.516578   -5.824792   -6.088688   -6.661309  ...  -41.372093   \n",
       "2  -84.124863  -95.908485  -98.228455 -101.852127  ... -174.743835   \n",
       "3   11.571680   11.357303   12.281723   13.987467  ...   65.480469   \n",
       "4    3.498780   -2.270911   -9.443663   -8.712378  ...  -91.412827   \n",
       "\n",
       "          207         208         209         210         211         212  \\\n",
       "0 -323.671509 -334.408813 -339.167542 -338.049377 -331.991302 -328.520233   \n",
       "1  -18.021332  -13.957712  -14.097721  -14.342066  -13.824280  -19.953529   \n",
       "2 -175.672638 -179.184937 -179.671829 -181.474518 -182.583771 -186.912994   \n",
       "3   54.011528   45.415066   47.022861   52.940224   50.364700   52.326881   \n",
       "4  -79.573364  -68.684639  -62.239941  -48.788322  -53.536591  -59.001015   \n",
       "\n",
       "          213         214         215  \n",
       "0 -321.373627 -314.663361 -300.228394  \n",
       "1  -27.281433  -24.620096  -22.640423  \n",
       "2 -188.352554 -176.718735 -133.417740  \n",
       "3   65.002045   67.655022   71.527222  \n",
       "4  -60.851425  -54.280022  -25.470638  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: chroma\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708295</td>\n",
       "      <td>0.640073</td>\n",
       "      <td>0.707260</td>\n",
       "      <td>0.544579</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.284966</td>\n",
       "      <td>0.254466</td>\n",
       "      <td>0.247745</td>\n",
       "      <td>0.324839</td>\n",
       "      <td>0.466124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114438</td>\n",
       "      <td>0.319022</td>\n",
       "      <td>0.370808</td>\n",
       "      <td>0.189577</td>\n",
       "      <td>0.042638</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.024571</td>\n",
       "      <td>0.025156</td>\n",
       "      <td>0.057726</td>\n",
       "      <td>0.065114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.595520</td>\n",
       "      <td>0.761191</td>\n",
       "      <td>0.617285</td>\n",
       "      <td>0.474223</td>\n",
       "      <td>0.340369</td>\n",
       "      <td>0.308571</td>\n",
       "      <td>0.460019</td>\n",
       "      <td>0.379475</td>\n",
       "      <td>0.303072</td>\n",
       "      <td>0.324227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102003</td>\n",
       "      <td>0.304017</td>\n",
       "      <td>0.354480</td>\n",
       "      <td>0.219087</td>\n",
       "      <td>0.042779</td>\n",
       "      <td>0.023521</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.015970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.703772</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511553</td>\n",
       "      <td>0.417635</td>\n",
       "      <td>0.389911</td>\n",
       "      <td>0.582626</td>\n",
       "      <td>0.537955</td>\n",
       "      <td>0.582327</td>\n",
       "      <td>0.628322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.346289</td>\n",
       "      <td>0.495336</td>\n",
       "      <td>0.291200</td>\n",
       "      <td>0.052698</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.022504</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.012317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.729621</td>\n",
       "      <td>0.740412</td>\n",
       "      <td>0.929025</td>\n",
       "      <td>0.534931</td>\n",
       "      <td>0.516650</td>\n",
       "      <td>0.398323</td>\n",
       "      <td>0.351357</td>\n",
       "      <td>0.400521</td>\n",
       "      <td>0.466655</td>\n",
       "      <td>0.598876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588484</td>\n",
       "      <td>0.842825</td>\n",
       "      <td>0.873660</td>\n",
       "      <td>0.598802</td>\n",
       "      <td>0.114322</td>\n",
       "      <td>0.032365</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.024819</td>\n",
       "      <td>0.015485</td>\n",
       "      <td>0.013818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966631</td>\n",
       "      <td>0.828872</td>\n",
       "      <td>0.708723</td>\n",
       "      <td>0.531631</td>\n",
       "      <td>0.500283</td>\n",
       "      <td>0.516987</td>\n",
       "      <td>0.690588</td>\n",
       "      <td>0.737944</td>\n",
       "      <td>0.609317</td>\n",
       "      <td>0.782331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807133</td>\n",
       "      <td>0.989460</td>\n",
       "      <td>0.916617</td>\n",
       "      <td>0.499404</td>\n",
       "      <td>0.099249</td>\n",
       "      <td>0.059439</td>\n",
       "      <td>0.052222</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>0.018052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.708295  0.640073  0.707260  0.544579  0.313167  0.284966  0.254466   \n",
       "1  0.595520  0.761191  0.617285  0.474223  0.340369  0.308571  0.460019   \n",
       "2  0.703772  0.855086  1.000000  0.511553  0.417635  0.389911  0.582626   \n",
       "3  0.729621  0.740412  0.929025  0.534931  0.516650  0.398323  0.351357   \n",
       "4  0.966631  0.828872  0.708723  0.531631  0.500283  0.516987  0.690588   \n",
       "\n",
       "        7         8         9    ...       206       207       208       209  \\\n",
       "0  0.247745  0.324839  0.466124  ...  0.114438  0.319022  0.370808  0.189577   \n",
       "1  0.379475  0.303072  0.324227  ...  0.102003  0.304017  0.354480  0.219087   \n",
       "2  0.537955  0.582327  0.628322  ...  0.233476  0.346289  0.495336  0.291200   \n",
       "3  0.400521  0.466655  0.598876  ...  0.588484  0.842825  0.873660  0.598802   \n",
       "4  0.737944  0.609317  0.782331  ...  0.807133  0.989460  0.916617  0.499404   \n",
       "\n",
       "        210       211       212       213       214       215  \n",
       "0  0.042638  0.022667  0.024571  0.025156  0.057726  0.065114  \n",
       "1  0.042779  0.023521  0.017317  0.014781  0.018537  0.015970  \n",
       "2  0.052698  0.023576  0.022504  0.014497  0.009743  0.012317  \n",
       "3  0.114322  0.032365  0.044700  0.024819  0.015485  0.013818  \n",
       "4  0.099249  0.059439  0.052222  0.020962  0.019204  0.018052  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: spectral_contrast\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.354793</td>\n",
       "      <td>11.055970</td>\n",
       "      <td>18.828681</td>\n",
       "      <td>13.490245</td>\n",
       "      <td>10.935963</td>\n",
       "      <td>17.737940</td>\n",
       "      <td>25.388246</td>\n",
       "      <td>23.359664</td>\n",
       "      <td>17.671976</td>\n",
       "      <td>16.888773</td>\n",
       "      <td>...</td>\n",
       "      <td>11.537984</td>\n",
       "      <td>17.709943</td>\n",
       "      <td>20.112632</td>\n",
       "      <td>13.965468</td>\n",
       "      <td>9.895126</td>\n",
       "      <td>7.356802</td>\n",
       "      <td>12.945463</td>\n",
       "      <td>12.272881</td>\n",
       "      <td>1.991081</td>\n",
       "      <td>0.512265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.655448</td>\n",
       "      <td>9.460604</td>\n",
       "      <td>13.589380</td>\n",
       "      <td>8.253302</td>\n",
       "      <td>6.355038</td>\n",
       "      <td>13.855677</td>\n",
       "      <td>5.488939</td>\n",
       "      <td>9.860909</td>\n",
       "      <td>11.352250</td>\n",
       "      <td>20.051979</td>\n",
       "      <td>...</td>\n",
       "      <td>10.357248</td>\n",
       "      <td>7.098002</td>\n",
       "      <td>13.164112</td>\n",
       "      <td>9.920544</td>\n",
       "      <td>10.515016</td>\n",
       "      <td>9.414235</td>\n",
       "      <td>11.883525</td>\n",
       "      <td>5.564786</td>\n",
       "      <td>6.395963</td>\n",
       "      <td>1.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.175265</td>\n",
       "      <td>17.008937</td>\n",
       "      <td>10.132582</td>\n",
       "      <td>9.868057</td>\n",
       "      <td>10.725284</td>\n",
       "      <td>9.491105</td>\n",
       "      <td>13.383158</td>\n",
       "      <td>10.775962</td>\n",
       "      <td>15.808067</td>\n",
       "      <td>12.061553</td>\n",
       "      <td>...</td>\n",
       "      <td>10.227426</td>\n",
       "      <td>11.273117</td>\n",
       "      <td>17.308825</td>\n",
       "      <td>12.270414</td>\n",
       "      <td>16.327901</td>\n",
       "      <td>13.583436</td>\n",
       "      <td>14.425934</td>\n",
       "      <td>16.306118</td>\n",
       "      <td>14.946777</td>\n",
       "      <td>10.478192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.181861</td>\n",
       "      <td>18.487100</td>\n",
       "      <td>7.492485</td>\n",
       "      <td>13.558920</td>\n",
       "      <td>11.697548</td>\n",
       "      <td>16.721800</td>\n",
       "      <td>12.770150</td>\n",
       "      <td>18.760126</td>\n",
       "      <td>14.912207</td>\n",
       "      <td>12.216167</td>\n",
       "      <td>...</td>\n",
       "      <td>10.045255</td>\n",
       "      <td>14.306967</td>\n",
       "      <td>15.011778</td>\n",
       "      <td>14.692581</td>\n",
       "      <td>13.983972</td>\n",
       "      <td>16.311010</td>\n",
       "      <td>12.784020</td>\n",
       "      <td>19.127118</td>\n",
       "      <td>17.829591</td>\n",
       "      <td>11.865277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.863674</td>\n",
       "      <td>11.875513</td>\n",
       "      <td>12.481405</td>\n",
       "      <td>14.705043</td>\n",
       "      <td>15.351461</td>\n",
       "      <td>15.150303</td>\n",
       "      <td>13.763269</td>\n",
       "      <td>11.776819</td>\n",
       "      <td>11.068494</td>\n",
       "      <td>17.253260</td>\n",
       "      <td>...</td>\n",
       "      <td>18.722942</td>\n",
       "      <td>19.851819</td>\n",
       "      <td>14.893240</td>\n",
       "      <td>17.568424</td>\n",
       "      <td>17.895550</td>\n",
       "      <td>21.664876</td>\n",
       "      <td>21.846788</td>\n",
       "      <td>22.297705</td>\n",
       "      <td>16.560607</td>\n",
       "      <td>15.399926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0   8.354793  11.055970  18.828681  13.490245  10.935963  17.737940   \n",
       "1   5.655448   9.460604  13.589380   8.253302   6.355038  13.855677   \n",
       "2   7.175265  17.008937  10.132582   9.868057  10.725284   9.491105   \n",
       "3  13.181861  18.487100   7.492485  13.558920  11.697548  16.721800   \n",
       "4  11.863674  11.875513  12.481405  14.705043  15.351461  15.150303   \n",
       "\n",
       "         6          7          8          9    ...        206        207  \\\n",
       "0  25.388246  23.359664  17.671976  16.888773  ...  11.537984  17.709943   \n",
       "1   5.488939   9.860909  11.352250  20.051979  ...  10.357248   7.098002   \n",
       "2  13.383158  10.775962  15.808067  12.061553  ...  10.227426  11.273117   \n",
       "3  12.770150  18.760126  14.912207  12.216167  ...  10.045255  14.306967   \n",
       "4  13.763269  11.776819  11.068494  17.253260  ...  18.722942  19.851819   \n",
       "\n",
       "         208        209        210        211        212        213  \\\n",
       "0  20.112632  13.965468   9.895126   7.356802  12.945463  12.272881   \n",
       "1  13.164112   9.920544  10.515016   9.414235  11.883525   5.564786   \n",
       "2  17.308825  12.270414  16.327901  13.583436  14.425934  16.306118   \n",
       "3  15.011778  14.692581  13.983972  16.311010  12.784020  19.127118   \n",
       "4  14.893240  17.568424  17.895550  21.664876  21.846788  22.297705   \n",
       "\n",
       "         214        215  \n",
       "0   1.991081   0.512265  \n",
       "1   6.395963   1.331900  \n",
       "2  14.946777  10.478192  \n",
       "3  17.829591  11.865277  \n",
       "4  16.560607  15.399926  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: tonnetz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053550</td>\n",
       "      <td>0.046576</td>\n",
       "      <td>0.069057</td>\n",
       "      <td>-0.033937</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.029023</td>\n",
       "      <td>0.030646</td>\n",
       "      <td>-0.002728</td>\n",
       "      <td>0.043914</td>\n",
       "      <td>0.068861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>-0.044043</td>\n",
       "      <td>-0.096815</td>\n",
       "      <td>-0.092799</td>\n",
       "      <td>-0.093778</td>\n",
       "      <td>-0.024391</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.040458</td>\n",
       "      <td>0.034045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006453</td>\n",
       "      <td>-0.015780</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.041921</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>0.015061</td>\n",
       "      <td>0.021392</td>\n",
       "      <td>-0.037868</td>\n",
       "      <td>-0.028053</td>\n",
       "      <td>0.050517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011720</td>\n",
       "      <td>-0.085404</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>-0.085780</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>-0.011803</td>\n",
       "      <td>-0.030609</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>-0.023262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059750</td>\n",
       "      <td>0.059457</td>\n",
       "      <td>0.074420</td>\n",
       "      <td>0.068720</td>\n",
       "      <td>0.029005</td>\n",
       "      <td>-0.084037</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>-0.014404</td>\n",
       "      <td>0.035721</td>\n",
       "      <td>0.032192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.045641</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>-0.021292</td>\n",
       "      <td>-0.084611</td>\n",
       "      <td>0.078510</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>-0.084613</td>\n",
       "      <td>0.032052</td>\n",
       "      <td>-0.095086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063891</td>\n",
       "      <td>0.044799</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.047675</td>\n",
       "      <td>0.045305</td>\n",
       "      <td>0.079124</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.129191</td>\n",
       "      <td>0.091020</td>\n",
       "      <td>0.047130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062414</td>\n",
       "      <td>-0.093077</td>\n",
       "      <td>0.102964</td>\n",
       "      <td>0.102695</td>\n",
       "      <td>-0.054047</td>\n",
       "      <td>0.059749</td>\n",
       "      <td>-0.066663</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-0.094087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003680</td>\n",
       "      <td>-0.011251</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>-0.045971</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>-0.042154</td>\n",
       "      <td>0.018350</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>-0.031041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034227</td>\n",
       "      <td>-0.024232</td>\n",
       "      <td>-0.041018</td>\n",
       "      <td>-0.120868</td>\n",
       "      <td>-0.063487</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>-0.023469</td>\n",
       "      <td>-0.047408</td>\n",
       "      <td>-0.042899</td>\n",
       "      <td>-0.044499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.053550  0.046576  0.069057 -0.033937  0.008213  0.029023  0.030646   \n",
       "1  0.006453 -0.015780  0.014258  0.041921  0.020128  0.015061  0.021392   \n",
       "2  0.059750  0.059457  0.074420  0.068720  0.029005 -0.084037  0.049583   \n",
       "3  0.063891  0.044799  0.006855  0.047675  0.045305  0.079124  0.070752   \n",
       "4 -0.003680 -0.011251  0.000642 -0.045971  0.009795 -0.042154  0.018350   \n",
       "\n",
       "        7         8         9    ...       206       207       208       209  \\\n",
       "0 -0.002728  0.043914  0.068861  ...  0.000652 -0.044043 -0.096815 -0.092799   \n",
       "1 -0.037868 -0.028053  0.050517  ... -0.011720 -0.085404  0.003190 -0.085780   \n",
       "2 -0.014404  0.035721  0.032192  ...  0.006173  0.045641  0.028443 -0.021292   \n",
       "3  0.129191  0.091020  0.047130  ... -0.062414 -0.093077  0.102964  0.102695   \n",
       "4  0.020736  0.005233 -0.031041  ... -0.034227 -0.024232 -0.041018 -0.120868   \n",
       "\n",
       "        210       211       212       213       214       215  \n",
       "0 -0.093778 -0.024391  0.022639  0.041814 -0.040458  0.034045  \n",
       "1  0.012057 -0.011803 -0.030609  0.036463 -0.000963 -0.023262  \n",
       "2 -0.084611  0.078510  0.001111 -0.084613  0.032052 -0.095086  \n",
       "3 -0.054047  0.059749 -0.066663  0.001458  0.000603 -0.094087  \n",
       "4 -0.063487  0.012695 -0.023469 -0.047408 -0.042899 -0.044499  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: spectral_centroid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7677.594522</td>\n",
       "      <td>6883.725464</td>\n",
       "      <td>5391.344823</td>\n",
       "      <td>4644.819335</td>\n",
       "      <td>4256.43529</td>\n",
       "      <td>4117.689942</td>\n",
       "      <td>4004.929086</td>\n",
       "      <td>3984.257218</td>\n",
       "      <td>4061.659922</td>\n",
       "      <td>4006.887847</td>\n",
       "      <td>...</td>\n",
       "      <td>5067.518515</td>\n",
       "      <td>4680.967893</td>\n",
       "      <td>4378.585674</td>\n",
       "      <td>4230.923206</td>\n",
       "      <td>3971.862278</td>\n",
       "      <td>3890.484845</td>\n",
       "      <td>3928.581672</td>\n",
       "      <td>4022.806</td>\n",
       "      <td>4128.249837</td>\n",
       "      <td>4278.453318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1            2            3           4    \\\n",
       "0  7677.594522  6883.725464  5391.344823  4644.819335  4256.43529   \n",
       "\n",
       "           5            6            7            8            9    ...  \\\n",
       "0  4117.689942  4004.929086  3984.257218  4061.659922  4006.887847  ...   \n",
       "\n",
       "           206          207          208          209          210  \\\n",
       "0  5067.518515  4680.967893  4378.585674  4230.923206  3971.862278   \n",
       "\n",
       "           211          212       213          214          215  \n",
       "0  3890.484845  3928.581672  4022.806  4128.249837  4278.453318  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: spectral_bandwidth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4317.705768</td>\n",
       "      <td>4241.620262</td>\n",
       "      <td>3764.47843</td>\n",
       "      <td>3102.94098</td>\n",
       "      <td>2587.063436</td>\n",
       "      <td>2375.034378</td>\n",
       "      <td>2266.970457</td>\n",
       "      <td>2138.180219</td>\n",
       "      <td>2141.049613</td>\n",
       "      <td>2112.659167</td>\n",
       "      <td>...</td>\n",
       "      <td>1282.843863</td>\n",
       "      <td>1538.289848</td>\n",
       "      <td>1647.334525</td>\n",
       "      <td>1606.466814</td>\n",
       "      <td>1534.741298</td>\n",
       "      <td>1504.182266</td>\n",
       "      <td>1461.898212</td>\n",
       "      <td>1388.453856</td>\n",
       "      <td>1453.93369</td>\n",
       "      <td>1711.389557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1           2           3            4            5    \\\n",
       "0  4317.705768  4241.620262  3764.47843  3102.94098  2587.063436  2375.034378   \n",
       "\n",
       "           6            7            8            9    ...          206  \\\n",
       "0  2266.970457  2138.180219  2141.049613  2112.659167  ...  1282.843863   \n",
       "\n",
       "           207          208          209          210          211  \\\n",
       "0  1538.289848  1647.334525  1606.466814  1534.741298  1504.182266   \n",
       "\n",
       "           212          213         214          215  \n",
       "0  1461.898212  1388.453856  1453.93369  1711.389557  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: spectral_rolloff\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13000.0</td>\n",
       "      <td>12156.25</td>\n",
       "      <td>10078.125</td>\n",
       "      <td>7750.0</td>\n",
       "      <td>6421.875</td>\n",
       "      <td>6343.75</td>\n",
       "      <td>6312.5</td>\n",
       "      <td>6078.125</td>\n",
       "      <td>6203.125</td>\n",
       "      <td>6015.625</td>\n",
       "      <td>...</td>\n",
       "      <td>6109.375</td>\n",
       "      <td>6093.75</td>\n",
       "      <td>5968.75</td>\n",
       "      <td>5796.875</td>\n",
       "      <td>5703.125</td>\n",
       "      <td>5515.625</td>\n",
       "      <td>5375.0</td>\n",
       "      <td>5375.0</td>\n",
       "      <td>5609.375</td>\n",
       "      <td>6031.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1          2       3         4        5       6         7    \\\n",
       "0  13000.0  12156.25  10078.125  7750.0  6421.875  6343.75  6312.5  6078.125   \n",
       "\n",
       "        8         9    ...       206      207      208       209       210  \\\n",
       "0  6203.125  6015.625  ...  6109.375  6093.75  5968.75  5796.875  5703.125   \n",
       "\n",
       "        211     212     213       214      215  \n",
       "0  5515.625  5375.0  5375.0  5609.375  6031.25  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: zero_crossing_rate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.223633</td>\n",
       "      <td>0.297852</td>\n",
       "      <td>0.361328</td>\n",
       "      <td>0.295898</td>\n",
       "      <td>0.250488</td>\n",
       "      <td>0.234863</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>0.245117</td>\n",
       "      <td>0.246582</td>\n",
       "      <td>0.242676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323242</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.258301</td>\n",
       "      <td>0.239258</td>\n",
       "      <td>0.218262</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.219727</td>\n",
       "      <td>0.186035</td>\n",
       "      <td>0.133789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.223633  0.297852  0.361328  0.295898  0.250488  0.234863  0.235352   \n",
       "\n",
       "        7         8         9    ...       206     207       208       209  \\\n",
       "0  0.245117  0.246582  0.242676  ...  0.323242  0.3125  0.288086  0.258301   \n",
       "\n",
       "        210       211       212       213       214       215  \n",
       "0  0.239258  0.218262  0.212891  0.219727  0.186035  0.133789  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: rms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090907</td>\n",
       "      <td>0.066837</td>\n",
       "      <td>0.030106</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0.035177</td>\n",
       "      <td>0.04654</td>\n",
       "      <td>0.061427</td>\n",
       "      <td>0.067807</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.057839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3        4         5         6    \\\n",
       "0  0.000013  0.000031  0.000073  0.000177  0.00027  0.000456  0.000616   \n",
       "\n",
       "        7         8         9    ...       206       207       208       209  \\\n",
       "0  0.000727  0.000869  0.000953  ...  0.090907  0.066837  0.030106  0.029994   \n",
       "\n",
       "        210      211       212       213       214       215  \n",
       "0  0.035177  0.04654  0.061427  0.067807  0.066481  0.057839  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "audio_features = extract_audio_features('./birdclef-2024/train_audio/asbfly/XC49755.ogg')\n",
    "\n",
    "# Convert features to a dictionary of DataFrames for better visualization\n",
    "features_df = {key: pd.DataFrame(value) for key, value in audio_features.items()}\n",
    "\n",
    "# Display the extracted features\n",
    "for feature_name, df in features_df.items():\n",
    "    print(f\"\\nFeature: {feature_name}\")\n",
    "    display(df.head())  # Using display() from IPython.display for better visualization in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(features):\n",
    "    aggregated_features = {}\n",
    "    for key, value in features.items():\n",
    "        aggregated_features[key] = {\n",
    "            'mean': np.mean(value, axis=1),\n",
    "            'std': np.std(value, axis=1),\n",
    "            'min': np.min(value, axis=1),\n",
    "            'max': np.max(value, axis=1)\n",
    "        }\n",
    "    return aggregated_features\n",
    "\n",
    "def format_features(aggregated_features):\n",
    "    formatted_features = []\n",
    "    for key in aggregated_features:\n",
    "        for stat in aggregated_features[key]:\n",
    "            formatted_features.extend(aggregated_features[key][stat])\n",
    "    return np.array(formatted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(684,)\n",
      "[-6.78951569e+01 -7.15780640e+01 -7.08037949e+01 -7.23653183e+01\n",
      " -7.57353821e+01 -7.60923462e+01 -7.72794800e+01 -7.69549332e+01\n",
      " -7.69535065e+01 -7.48166962e+01 -7.59738770e+01 -7.50231094e+01\n",
      " -7.48816452e+01 -7.21270599e+01 -7.18847809e+01 -6.99784622e+01\n",
      " -6.92440033e+01 -6.64677048e+01 -6.55641098e+01 -6.29078407e+01\n",
      " -6.35348587e+01 -6.19041100e+01 -6.14968414e+01 -6.00429764e+01\n",
      " -5.98880310e+01 -5.87049522e+01 -5.84746971e+01 -5.72715187e+01\n",
      " -5.75240135e+01 -5.58471870e+01 -5.55498352e+01 -5.40977554e+01\n",
      " -5.38592224e+01 -5.26902885e+01 -5.27443390e+01 -5.14852333e+01\n",
      " -5.19623528e+01 -5.10422897e+01 -5.14217949e+01 -5.06474075e+01\n",
      " -5.04771423e+01 -4.96308174e+01 -5.02442932e+01 -4.85827980e+01\n",
      " -4.86090584e+01 -4.86892738e+01 -4.79537125e+01 -4.74637413e+01\n",
      " -4.74799500e+01 -4.70840187e+01 -4.66258774e+01 -4.66038132e+01\n",
      " -4.59247398e+01 -4.57369804e+01 -4.46376686e+01 -4.42834740e+01\n",
      " -4.41352196e+01 -4.43094559e+01 -4.40298653e+01 -4.37026901e+01\n",
      " -4.32755165e+01 -4.15394707e+01 -3.99824142e+01 -3.92749367e+01\n",
      " -3.92779465e+01 -3.87621880e+01 -3.89020996e+01 -3.95993652e+01\n",
      " -3.94569855e+01 -3.88339195e+01 -3.77464409e+01 -3.76755600e+01\n",
      " -3.86658936e+01 -3.90819778e+01 -4.00564690e+01 -3.94911041e+01\n",
      " -3.94883385e+01 -3.96045380e+01 -3.94877930e+01 -3.88125076e+01\n",
      " -3.85692368e+01 -3.84432793e+01 -3.79438934e+01 -3.67786636e+01\n",
      " -3.60531273e+01 -3.50859528e+01 -3.31388969e+01 -3.15234241e+01\n",
      " -3.29588699e+01 -3.34340057e+01 -3.32153320e+01 -3.30964012e+01\n",
      " -3.21221428e+01 -3.20766640e+01 -3.23976784e+01 -3.35128937e+01\n",
      " -3.53165016e+01 -3.57124748e+01 -3.53675613e+01 -3.51138268e+01\n",
      " -3.53335991e+01 -3.51394196e+01 -3.54274139e+01 -3.58785133e+01\n",
      " -3.50933533e+01 -3.49577370e+01 -3.44668770e+01 -3.33479576e+01\n",
      " -3.35960121e+01 -3.35661087e+01 -3.43455620e+01 -3.52197037e+01\n",
      " -3.56412086e+01 -3.67417564e+01 -3.71535378e+01 -3.82551422e+01\n",
      " -3.89039726e+01 -3.93453941e+01 -4.11509705e+01 -4.36231461e+01\n",
      " -4.62478561e+01 -4.63357735e+01 -4.67927780e+01 -4.65924492e+01\n",
      " -4.74542236e+01 -4.95269623e+01 -5.05189056e+01 -5.26859665e+01\n",
      "  6.56299448e+00  6.18674850e+00  6.55345249e+00  5.51750898e+00\n",
      "  4.18041134e+00  4.23090696e+00  3.52300167e+00  3.76272321e+00\n",
      "  3.88103509e+00  4.66800356e+00  4.14625502e+00  4.58000612e+00\n",
      "  4.80571890e+00  5.48072720e+00  5.57625580e+00  6.21433544e+00\n",
      "  6.24613905e+00  6.18533564e+00  6.36747169e+00  6.70571947e+00\n",
      "  7.04883575e+00  6.95166397e+00  7.01741982e+00  7.15030336e+00\n",
      "  6.66945076e+00  6.77303505e+00  6.60638714e+00  6.78836250e+00\n",
      "  7.33285570e+00  7.65487671e+00  7.20324278e+00  7.25675488e+00\n",
      "  7.44987154e+00  7.43501425e+00  7.61926603e+00  7.73002291e+00\n",
      "  8.07750893e+00  8.22564697e+00  8.29813480e+00  8.07737827e+00\n",
      "  7.72395992e+00  7.92968988e+00  7.91483164e+00  7.62226868e+00\n",
      "  8.00218964e+00  7.69910574e+00  7.59039450e+00  7.76662970e+00\n",
      "  8.30974960e+00  8.12859058e+00  8.16521549e+00  8.16108894e+00\n",
      "  8.06208038e+00  8.64978027e+00  7.88691998e+00  7.88651323e+00\n",
      "  8.45182991e+00  8.15819359e+00  8.03371143e+00  7.80946159e+00\n",
      "  8.20490742e+00  8.17265511e+00  8.35328579e+00  8.57586479e+00\n",
      "  8.34617424e+00  8.30582714e+00  8.58960915e+00  8.80618191e+00\n",
      "  8.86267662e+00  1.05642033e+01  1.14022331e+01  1.11419153e+01\n",
      "  1.06528606e+01  9.42436409e+00  9.12918854e+00  9.68060970e+00\n",
      "  9.20140266e+00  9.09740639e+00  9.50028229e+00  9.99795818e+00\n",
      "  9.65746117e+00  9.29731369e+00  9.82576370e+00  1.01280441e+01\n",
      "  1.06159306e+01  1.11368818e+01  1.23328352e+01  1.34491043e+01\n",
      "  1.18223820e+01  1.10503883e+01  1.09108925e+01  1.06719265e+01\n",
      "  1.09011621e+01  1.12801561e+01  1.20857611e+01  1.12677145e+01\n",
      "  1.08428488e+01  1.07253704e+01  1.10011864e+01  1.18069811e+01\n",
      "  1.18015528e+01  1.22768888e+01  1.24530239e+01  1.22428036e+01\n",
      "  1.28905382e+01  1.36546593e+01  1.39125195e+01  1.42805138e+01\n",
      "  1.41864090e+01  1.46822739e+01  1.43236561e+01  1.40023136e+01\n",
      "  1.32522650e+01  1.20269718e+01  1.24992142e+01  1.25431204e+01\n",
      "  1.28116131e+01  1.27642851e+01  1.19424372e+01  1.12910728e+01\n",
      "  1.11514626e+01  1.02449818e+01  1.11749325e+01  1.22489347e+01\n",
      "  1.25241871e+01  1.15843544e+01  1.16579790e+01  1.18155575e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -8.00000000e+01 -8.00000000e+01 -8.00000000e+01 -8.00000000e+01\n",
      " -5.58989983e+01 -5.53959618e+01 -5.41812973e+01 -5.73548889e+01\n",
      " -5.83251114e+01 -5.71344910e+01 -5.75622215e+01 -5.79604683e+01\n",
      " -5.83976135e+01 -5.69162674e+01 -5.75878296e+01 -5.60618629e+01\n",
      " -5.50282974e+01 -5.40371857e+01 -5.43599167e+01 -5.18604851e+01\n",
      " -5.38039742e+01 -5.16452866e+01 -5.41225090e+01 -5.16966972e+01\n",
      " -5.20693436e+01 -4.94093895e+01 -4.70459824e+01 -4.82545662e+01\n",
      " -4.81084404e+01 -4.82258759e+01 -4.76104126e+01 -4.33761940e+01\n",
      " -4.47535896e+01 -4.39473267e+01 -4.41831665e+01 -4.31752701e+01\n",
      " -4.27493286e+01 -4.07317505e+01 -4.05458221e+01 -3.97431412e+01\n",
      " -4.04049149e+01 -3.68087997e+01 -3.79459915e+01 -3.91301994e+01\n",
      " -4.03443451e+01 -3.89789505e+01 -3.88422165e+01 -3.70711975e+01\n",
      " -3.79855576e+01 -3.90382538e+01 -3.56820030e+01 -3.58552933e+01\n",
      " -3.61914864e+01 -3.70150146e+01 -3.58783340e+01 -3.54745102e+01\n",
      " -3.41478653e+01 -3.54403305e+01 -3.49919510e+01 -3.37266884e+01\n",
      " -3.25184631e+01 -3.41697502e+01 -3.31934738e+01 -3.42239304e+01\n",
      " -2.90324287e+01 -2.81320724e+01 -2.88013763e+01 -2.80316296e+01\n",
      " -2.82570419e+01 -2.85703602e+01 -2.78563728e+01 -2.27793846e+01\n",
      " -2.02830105e+01 -9.31635189e+00 -6.44812393e+00 -1.29913139e+01\n",
      " -1.47169743e+01 -2.24343472e+01 -2.91979141e+01 -2.57494621e+01\n",
      " -2.54320374e+01 -2.24489536e+01 -2.46336040e+01 -2.46523056e+01\n",
      " -2.11715031e+01 -2.32916107e+01 -2.47804298e+01 -2.35608349e+01\n",
      " -2.10312634e+01 -1.83106289e+01 -1.32193012e+01 -1.04374714e+01\n",
      " -1.37160959e+01 -1.26200771e+01 -1.11487732e+01 -1.67393608e+01\n",
      " -9.03981781e+00 -7.31603050e+00 -8.54920578e+00 -9.53508854e+00\n",
      " -7.58930969e+00 -1.09238672e+01 -1.24443722e+01 -1.01276379e+01\n",
      " -9.14618683e+00 -9.87414932e+00 -6.04185486e+00 -9.62997246e+00\n",
      " -7.19623661e+00 -1.26617241e+00 -3.28722000e+00 -3.13824272e+00\n",
      " -2.87443161e-01 -1.68604469e+00  0.00000000e+00 -6.46774292e-01\n",
      " -3.31578827e+00 -8.79345417e+00 -5.26008987e+00 -3.25497818e+00\n",
      " -1.62715340e+00 -2.09276581e+00 -6.58005238e+00 -1.85611172e+01\n",
      " -2.38423748e+01 -2.52900162e+01 -2.22083569e+01 -1.10508595e+01\n",
      " -8.56939220e+00 -1.62574615e+01 -1.27492228e+01 -1.36126022e+01\n",
      " -3.78031799e+02 -9.77883911e+00 -1.62413513e+02  3.93792458e+01\n",
      " -4.95024490e+01 -6.25760555e-01 -3.73189735e+00 -7.72480106e+00\n",
      "  5.14817095e+00 -9.43658173e-01  8.90023899e+00  4.81888485e+00\n",
      "  2.91285347e-02  8.03989258e+01  1.78389187e+01  3.11695137e+01\n",
      "  1.88223610e+01  1.95934772e+01  9.88203430e+00  9.81474876e+00\n",
      "  9.35540676e+00  6.19378090e+00  6.64263439e+00  8.38670349e+00\n",
      "  7.03471041e+00  6.25368261e+00 -6.95373413e+02 -6.44163055e+01\n",
      " -1.98375519e+02 -2.97238398e-03 -9.14128265e+01 -1.87220078e+01\n",
      " -2.72821121e+01 -3.06996994e+01 -1.04680920e+01 -1.74845657e+01\n",
      " -1.79145947e+01 -1.83506489e+01 -1.67871647e+01 -2.93432312e+02\n",
      "  2.18189926e+01  0.00000000e+00  8.81842575e+01  1.15289097e+01\n",
      "  2.74193649e+01  1.70098763e+01  1.13695221e+01  2.45030174e+01\n",
      "  2.21738167e+01  2.91056252e+01  2.93264084e+01  2.02210732e+01\n",
      "  3.57199669e-01  3.07124913e-01  3.35543245e-01  3.79172206e-01\n",
      "  3.74025345e-01  3.68796736e-01  5.04714608e-01  5.14655232e-01\n",
      "  4.76456851e-01  5.64261794e-01  4.03102040e-01  3.45245868e-01\n",
      "  2.93734103e-01  2.65951812e-01  2.80152529e-01  2.76178867e-01\n",
      "  2.77236491e-01  2.68116444e-01  3.31215024e-01  3.24809521e-01\n",
      "  3.44703048e-01  3.66285741e-01  2.83933997e-01  2.77644515e-01\n",
      "  1.67002832e-03  3.50483810e-03  3.55488108e-03  3.75877111e-03\n",
      "  6.80759642e-03  1.12461336e-02  1.24585917e-02  4.05499246e-03\n",
      "  1.84830569e-03  1.53691496e-03  1.69276062e-03  1.32982619e-03\n",
      "  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "  1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "  1.62796840e+01  1.06705893e+01  1.42380687e+01  1.45769883e+01\n",
      "  1.70175472e+01  1.90484405e+01  6.91645007e+01  5.76671939e+00\n",
      "  3.39324799e+00  3.19839626e+00  3.02200336e+00  3.37177983e+00\n",
      "  3.76862514e+00  9.06251354e+00  5.12264553e-01  1.33189977e+00\n",
      "  6.94615049e+00  7.49248545e+00  9.89702858e+00  1.29031502e+01\n",
      "  1.64578900e+01  4.13874441e+01  2.38273993e+01  2.72583739e+01\n",
      "  2.54605702e+01  2.47335460e+01  3.22489909e+01  8.43767014e+01\n",
      "  3.01676464e-02 -4.96030862e-02  8.57828109e-03 -1.20755398e-02\n",
      " -2.17345903e-02  2.96799421e-02  7.32131957e-02  8.62107497e-02\n",
      "  8.40756654e-02  1.11186105e-01  4.14829638e-02  4.96818389e-02\n",
      " -1.32700045e-01 -3.35049950e-01 -2.59177864e-01 -3.18522770e-01\n",
      " -1.80899387e-01 -8.71330742e-02  3.30933152e-01  1.39883232e-01\n",
      "  2.68008487e-01  2.97368016e-01  8.07791594e-02  2.04888635e-01\n",
      "  4.20911135e+03  5.54060369e+02  3.51706073e+03  7.67759452e+03\n",
      "  1.70350726e+03  3.90775028e+02  9.74245254e+02  4.31770577e+03\n",
      "  5.86841725e+03  8.78995727e+02  4.96875000e+03  1.30000000e+04\n",
      "  2.51867224e-01  4.45658672e-02  1.33789062e-01  4.06738281e-01\n",
      "  3.53122093e-02  3.67540419e-02  1.29457030e-05  1.58307001e-01]\n"
     ]
    }
   ],
   "source": [
    "ogg_file_path = './birdclef-2024/train_audio/asbfly/XC49755.ogg'\n",
    "max_length = 22050 * 5  # For example, 5 seconds at a sample rate of 22050 Hz\n",
    "\n",
    "# Extract and aggregate features\n",
    "features = extract_audio_features(ogg_file_path, max_length)\n",
    "aggregated_features = aggregate_features(features)\n",
    "\n",
    "# Format features for model input\n",
    "formatted_features = format_features(aggregated_features)\n",
    "\n",
    "print(formatted_features.shape)\n",
    "print(formatted_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24459 files.\n",
      "(24459, 684)\n",
      "(24459, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def extract_and_format_features(file_path, max_length=22050*5):\n",
    "    try:\n",
    "        features = extract_audio_features(file_path, max_length)\n",
    "        aggregated_features = aggregate_features(features)\n",
    "        formatted_features = format_features(aggregated_features)\n",
    "        return formatted_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_batch(file_paths, labels, max_length):\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    for file_path, label in zip(file_paths, labels):\n",
    "        formatted_features = extract_and_format_features(file_path, max_length)\n",
    "        if formatted_features is not None:\n",
    "            X_batch.append(formatted_features)\n",
    "            y_batch.append(label)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "def load_data(file_paths, labels, max_length=22050*5, batch_size=1000):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Split the data into batches\n",
    "    batches = [(file_paths[i:i + batch_size], labels[i:i + batch_size])\n",
    "               for i in range(0, len(file_paths), batch_size)]\n",
    "\n",
    "    # Process batches in parallel using ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_batch, batch_files, batch_labels, max_length) \n",
    "                   for batch_files, batch_labels in batches]\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            X_batch, y_batch = future.result()\n",
    "            X.extend(X_batch)\n",
    "            y.extend(y_batch)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Assuming df_train is already loaded in your notebook\n",
    "file_paths = df_train['filename'].apply(lambda x: \"./birdclef-2024/train_audio/\" + x).tolist()\n",
    "labels = df_train['primary_label'].astype('category').cat.codes.tolist()\n",
    "\n",
    "# Load data\n",
    "X, y =  pd.read_csv('X.csv', header=None), pd.read_csv('y.csv', header=None) #load_data(file_paths, labels)\n",
    "\n",
    "print(f\"Loaded {X.shape[0]} files.\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24459, 684)\n",
      "(24459, 1)\n"
     ]
    }
   ],
   "source": [
    "# save x and y as csv\n",
    "\n",
    "# np.savetxt('X.csv', X, delimiter=',')\n",
    "# np.savetxt('y.csv', y, delimiter=',')\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24459, 684) (24459, 182)\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rami\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0218 - loss: 5.0534 - val_accuracy: 0.1034 - val_loss: 4.3542\n",
      "Epoch 2/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0795 - loss: 4.3151 - val_accuracy: 0.1547 - val_loss: 3.9201\n",
      "Epoch 3/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1203 - loss: 3.9716 - val_accuracy: 0.1868 - val_loss: 3.7069\n",
      "Epoch 4/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1425 - loss: 3.7976 - val_accuracy: 0.1999 - val_loss: 3.5576\n",
      "Epoch 5/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1642 - loss: 3.6386 - val_accuracy: 0.2255 - val_loss: 3.4657\n",
      "Epoch 6/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1847 - loss: 3.5475 - val_accuracy: 0.2265 - val_loss: 3.3832\n",
      "Epoch 7/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1964 - loss: 3.4542 - val_accuracy: 0.2478 - val_loss: 3.3055\n",
      "Epoch 8/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2056 - loss: 3.4356 - val_accuracy: 0.2619 - val_loss: 3.2558\n",
      "Epoch 9/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2232 - loss: 3.3362 - val_accuracy: 0.2625 - val_loss: 3.2201\n",
      "Epoch 10/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2215 - loss: 3.3214 - val_accuracy: 0.2655 - val_loss: 3.1687\n",
      "Epoch 11/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2364 - loss: 3.2662 - val_accuracy: 0.2790 - val_loss: 3.1406\n",
      "Epoch 12/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2388 - loss: 3.2381 - val_accuracy: 0.2835 - val_loss: 3.1184\n",
      "Epoch 13/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2412 - loss: 3.2185 - val_accuracy: 0.2897 - val_loss: 3.0807\n",
      "Epoch 14/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2574 - loss: 3.1363 - val_accuracy: 0.2923 - val_loss: 3.0570\n",
      "Epoch 15/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2547 - loss: 3.1370 - val_accuracy: 0.3005 - val_loss: 3.0219\n",
      "Epoch 16/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2622 - loss: 3.1158 - val_accuracy: 0.3052 - val_loss: 3.0079\n",
      "Epoch 17/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2670 - loss: 3.0783 - val_accuracy: 0.3025 - val_loss: 2.9997\n",
      "Epoch 18/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2633 - loss: 3.0819 - val_accuracy: 0.3040 - val_loss: 2.9876\n",
      "Epoch 19/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2738 - loss: 3.0398 - val_accuracy: 0.3138 - val_loss: 2.9586\n",
      "Epoch 20/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2764 - loss: 3.0398 - val_accuracy: 0.3132 - val_loss: 2.9429\n",
      "Epoch 21/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2820 - loss: 3.0326 - val_accuracy: 0.3185 - val_loss: 2.9178\n",
      "Epoch 22/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2898 - loss: 2.9798 - val_accuracy: 0.3132 - val_loss: 2.9317\n",
      "Epoch 23/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2937 - loss: 2.9612 - val_accuracy: 0.3203 - val_loss: 2.9043\n",
      "Epoch 24/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2960 - loss: 2.9346 - val_accuracy: 0.3187 - val_loss: 2.8990\n",
      "Epoch 25/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3015 - loss: 2.9492 - val_accuracy: 0.3279 - val_loss: 2.8779\n",
      "Epoch 26/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2958 - loss: 2.9500 - val_accuracy: 0.3279 - val_loss: 2.8638\n",
      "Epoch 27/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2997 - loss: 2.8942 - val_accuracy: 0.3354 - val_loss: 2.8513\n",
      "Epoch 28/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3024 - loss: 2.8908 - val_accuracy: 0.3285 - val_loss: 2.8484\n",
      "Epoch 29/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3058 - loss: 2.8826 - val_accuracy: 0.3336 - val_loss: 2.8300\n",
      "Epoch 30/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3047 - loss: 2.8752 - val_accuracy: 0.3379 - val_loss: 2.8344\n",
      "Epoch 31/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3047 - loss: 2.8581 - val_accuracy: 0.3334 - val_loss: 2.8278\n",
      "Epoch 32/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3133 - loss: 2.8352 - val_accuracy: 0.3397 - val_loss: 2.8323\n",
      "Epoch 33/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3125 - loss: 2.8664 - val_accuracy: 0.3422 - val_loss: 2.8091\n",
      "Epoch 34/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3123 - loss: 2.8360 - val_accuracy: 0.3397 - val_loss: 2.8117\n",
      "Epoch 35/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3167 - loss: 2.8101 - val_accuracy: 0.3438 - val_loss: 2.8064\n",
      "Epoch 36/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3181 - loss: 2.7976 - val_accuracy: 0.3383 - val_loss: 2.7959\n",
      "Epoch 37/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3271 - loss: 2.7899 - val_accuracy: 0.3422 - val_loss: 2.7896\n",
      "Epoch 38/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3223 - loss: 2.7857 - val_accuracy: 0.3461 - val_loss: 2.7932\n",
      "Epoch 39/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3262 - loss: 2.7533 - val_accuracy: 0.3442 - val_loss: 2.7856\n",
      "Epoch 40/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3229 - loss: 2.7852 - val_accuracy: 0.3442 - val_loss: 2.7799\n",
      "Epoch 41/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3197 - loss: 2.7579 - val_accuracy: 0.3502 - val_loss: 2.7625\n",
      "Epoch 42/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3263 - loss: 2.7495 - val_accuracy: 0.3471 - val_loss: 2.7644\n",
      "Epoch 43/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3267 - loss: 2.7417 - val_accuracy: 0.3453 - val_loss: 2.7654\n",
      "Epoch 44/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3430 - loss: 2.7109 - val_accuracy: 0.3547 - val_loss: 2.7578\n",
      "Epoch 45/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3335 - loss: 2.7234 - val_accuracy: 0.3571 - val_loss: 2.7537\n",
      "Epoch 46/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3399 - loss: 2.7046 - val_accuracy: 0.3506 - val_loss: 2.7512\n",
      "Epoch 47/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3335 - loss: 2.7276 - val_accuracy: 0.3522 - val_loss: 2.7526\n",
      "Epoch 48/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3376 - loss: 2.7063 - val_accuracy: 0.3590 - val_loss: 2.7415\n",
      "Epoch 49/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3411 - loss: 2.6898 - val_accuracy: 0.3563 - val_loss: 2.7442\n",
      "Epoch 50/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3350 - loss: 2.6766 - val_accuracy: 0.3496 - val_loss: 2.7493\n",
      "Epoch 51/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3414 - loss: 2.7013 - val_accuracy: 0.3538 - val_loss: 2.7362\n",
      "Epoch 52/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3377 - loss: 2.6950 - val_accuracy: 0.3592 - val_loss: 2.7264\n",
      "Epoch 53/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3409 - loss: 2.6607 - val_accuracy: 0.3540 - val_loss: 2.7388\n",
      "Epoch 54/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3449 - loss: 2.6423 - val_accuracy: 0.3622 - val_loss: 2.7381\n",
      "Epoch 55/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3399 - loss: 2.6754 - val_accuracy: 0.3647 - val_loss: 2.7265\n",
      "Epoch 56/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3443 - loss: 2.6405 - val_accuracy: 0.3604 - val_loss: 2.7206\n",
      "Epoch 57/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3458 - loss: 2.6530 - val_accuracy: 0.3628 - val_loss: 2.7262\n",
      "Epoch 58/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3427 - loss: 2.6582 - val_accuracy: 0.3618 - val_loss: 2.7215\n",
      "Epoch 59/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3523 - loss: 2.6346 - val_accuracy: 0.3635 - val_loss: 2.7209\n",
      "Epoch 60/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3479 - loss: 2.6118 - val_accuracy: 0.3604 - val_loss: 2.7207\n",
      "Epoch 61/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3373 - loss: 2.6370 - val_accuracy: 0.3606 - val_loss: 2.7221\n",
      "Epoch 62/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3503 - loss: 2.6271 - val_accuracy: 0.3620 - val_loss: 2.7071\n",
      "Epoch 63/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3583 - loss: 2.5797 - val_accuracy: 0.3626 - val_loss: 2.7099\n",
      "Epoch 64/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3591 - loss: 2.5747 - val_accuracy: 0.3616 - val_loss: 2.7023\n",
      "Epoch 65/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3666 - loss: 2.5591 - val_accuracy: 0.3663 - val_loss: 2.6985\n",
      "Epoch 66/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3575 - loss: 2.5974 - val_accuracy: 0.3626 - val_loss: 2.7111\n",
      "Epoch 67/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3606 - loss: 2.5767 - val_accuracy: 0.3653 - val_loss: 2.7073\n",
      "Epoch 68/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3626 - loss: 2.5558 - val_accuracy: 0.3692 - val_loss: 2.7034\n",
      "Epoch 69/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3655 - loss: 2.5708 - val_accuracy: 0.3673 - val_loss: 2.6825\n",
      "Epoch 70/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3607 - loss: 2.5641 - val_accuracy: 0.3741 - val_loss: 2.6901\n",
      "Epoch 71/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3546 - loss: 2.5753 - val_accuracy: 0.3702 - val_loss: 2.6900\n",
      "Epoch 72/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3602 - loss: 2.5583 - val_accuracy: 0.3769 - val_loss: 2.6817\n",
      "Epoch 73/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3627 - loss: 2.5410 - val_accuracy: 0.3688 - val_loss: 2.6977\n",
      "Epoch 74/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3620 - loss: 2.5524 - val_accuracy: 0.3643 - val_loss: 2.6926\n",
      "Epoch 75/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3643 - loss: 2.5521 - val_accuracy: 0.3731 - val_loss: 2.6869\n",
      "Epoch 76/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3538 - loss: 2.5646 - val_accuracy: 0.3712 - val_loss: 2.6928\n",
      "Epoch 77/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3709 - loss: 2.5175 - val_accuracy: 0.3806 - val_loss: 2.6818\n",
      "Epoch 78/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3708 - loss: 2.5346 - val_accuracy: 0.3696 - val_loss: 2.6890\n",
      "Epoch 79/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3698 - loss: 2.5138 - val_accuracy: 0.3739 - val_loss: 2.6857\n",
      "Epoch 80/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3732 - loss: 2.5085 - val_accuracy: 0.3731 - val_loss: 2.6910\n",
      "Epoch 81/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3711 - loss: 2.5141 - val_accuracy: 0.3686 - val_loss: 2.6879\n",
      "Epoch 82/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3726 - loss: 2.5251 - val_accuracy: 0.3771 - val_loss: 2.6825\n",
      "Epoch 83/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3680 - loss: 2.5355 - val_accuracy: 0.3704 - val_loss: 2.6776\n",
      "Epoch 84/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3766 - loss: 2.5019 - val_accuracy: 0.3757 - val_loss: 2.6785\n",
      "Epoch 85/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3637 - loss: 2.5200 - val_accuracy: 0.3708 - val_loss: 2.6672\n",
      "Epoch 86/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3754 - loss: 2.4984 - val_accuracy: 0.3743 - val_loss: 2.6735\n",
      "Epoch 87/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3828 - loss: 2.4618 - val_accuracy: 0.3739 - val_loss: 2.6670\n",
      "Epoch 88/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3784 - loss: 2.4663 - val_accuracy: 0.3700 - val_loss: 2.6805\n",
      "Epoch 89/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3793 - loss: 2.4696 - val_accuracy: 0.3800 - val_loss: 2.6699\n",
      "Epoch 90/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3835 - loss: 2.4572 - val_accuracy: 0.3761 - val_loss: 2.6667\n",
      "Epoch 91/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3782 - loss: 2.4537 - val_accuracy: 0.3749 - val_loss: 2.6739\n",
      "Epoch 92/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3747 - loss: 2.4514 - val_accuracy: 0.3747 - val_loss: 2.6687\n",
      "Epoch 93/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3748 - loss: 2.4739 - val_accuracy: 0.3765 - val_loss: 2.6792\n",
      "Epoch 94/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3778 - loss: 2.4519 - val_accuracy: 0.3774 - val_loss: 2.6723\n",
      "Epoch 95/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3819 - loss: 2.4347 - val_accuracy: 0.3835 - val_loss: 2.6668\n",
      "Epoch 96/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3808 - loss: 2.4570 - val_accuracy: 0.3710 - val_loss: 2.6735\n",
      "Epoch 97/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3838 - loss: 2.4493 - val_accuracy: 0.3765 - val_loss: 2.6652\n",
      "Epoch 98/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3890 - loss: 2.4455 - val_accuracy: 0.3808 - val_loss: 2.6687\n",
      "Epoch 99/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3862 - loss: 2.4381 - val_accuracy: 0.3751 - val_loss: 2.6694\n",
      "Epoch 100/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3865 - loss: 2.4142 - val_accuracy: 0.3859 - val_loss: 2.6663\n",
      "Epoch 101/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3896 - loss: 2.4170 - val_accuracy: 0.3749 - val_loss: 2.6723\n",
      "Epoch 102/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3903 - loss: 2.4334 - val_accuracy: 0.3847 - val_loss: 2.6627\n",
      "Epoch 103/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3792 - loss: 2.4432 - val_accuracy: 0.3765 - val_loss: 2.6586\n",
      "Epoch 104/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3878 - loss: 2.4188 - val_accuracy: 0.3794 - val_loss: 2.6609\n",
      "Epoch 105/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3861 - loss: 2.4182 - val_accuracy: 0.3849 - val_loss: 2.6550\n",
      "Epoch 106/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3901 - loss: 2.4211 - val_accuracy: 0.3786 - val_loss: 2.6556\n",
      "Epoch 107/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3901 - loss: 2.4105 - val_accuracy: 0.3782 - val_loss: 2.6696\n",
      "Epoch 108/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3879 - loss: 2.4115 - val_accuracy: 0.3749 - val_loss: 2.6790\n",
      "Epoch 109/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3921 - loss: 2.4166 - val_accuracy: 0.3763 - val_loss: 2.6696\n",
      "Epoch 110/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3876 - loss: 2.4314 - val_accuracy: 0.3759 - val_loss: 2.6603\n",
      "Epoch 111/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3957 - loss: 2.4000 - val_accuracy: 0.3774 - val_loss: 2.6719\n",
      "Epoch 112/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3894 - loss: 2.3913 - val_accuracy: 0.3743 - val_loss: 2.6752\n",
      "Epoch 113/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3877 - loss: 2.4271 - val_accuracy: 0.3771 - val_loss: 2.6704\n",
      "Epoch 114/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3874 - loss: 2.4263 - val_accuracy: 0.3794 - val_loss: 2.6670\n",
      "Epoch 115/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3972 - loss: 2.3842 - val_accuracy: 0.3743 - val_loss: 2.6774\n",
      "Epoch 116/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3942 - loss: 2.3799 - val_accuracy: 0.3810 - val_loss: 2.6673\n",
      "Epoch 117/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3993 - loss: 2.3738 - val_accuracy: 0.3816 - val_loss: 2.6699\n",
      "Epoch 118/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3948 - loss: 2.3897 - val_accuracy: 0.3753 - val_loss: 2.6633\n",
      "Epoch 119/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3934 - loss: 2.4060 - val_accuracy: 0.3833 - val_loss: 2.6653\n",
      "Epoch 120/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3977 - loss: 2.3834 - val_accuracy: 0.3841 - val_loss: 2.6740\n",
      "Epoch 121/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3933 - loss: 2.3868 - val_accuracy: 0.3806 - val_loss: 2.6718\n",
      "Epoch 122/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3975 - loss: 2.3853 - val_accuracy: 0.3769 - val_loss: 2.6693\n",
      "Epoch 123/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3969 - loss: 2.3994 - val_accuracy: 0.3792 - val_loss: 2.6686\n",
      "Epoch 124/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3962 - loss: 2.3796 - val_accuracy: 0.3804 - val_loss: 2.6666\n",
      "Epoch 125/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4044 - loss: 2.3606 - val_accuracy: 0.3780 - val_loss: 2.6665\n",
      "Epoch 126/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3950 - loss: 2.3634 - val_accuracy: 0.3796 - val_loss: 2.6617\n",
      "Epoch 127/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3995 - loss: 2.3638 - val_accuracy: 0.3810 - val_loss: 2.6679\n",
      "Epoch 128/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4059 - loss: 2.3566 - val_accuracy: 0.3847 - val_loss: 2.6536\n",
      "Epoch 129/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3935 - loss: 2.3676 - val_accuracy: 0.3872 - val_loss: 2.6577\n",
      "Epoch 130/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4039 - loss: 2.3366 - val_accuracy: 0.3853 - val_loss: 2.6547\n",
      "Epoch 131/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3989 - loss: 2.3726 - val_accuracy: 0.3743 - val_loss: 2.6650\n",
      "Epoch 132/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4057 - loss: 2.3379 - val_accuracy: 0.3810 - val_loss: 2.6641\n",
      "Epoch 133/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4102 - loss: 2.3248 - val_accuracy: 0.3870 - val_loss: 2.6504\n",
      "Epoch 134/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4076 - loss: 2.3342 - val_accuracy: 0.3851 - val_loss: 2.6478\n",
      "Epoch 135/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4037 - loss: 2.3503 - val_accuracy: 0.3859 - val_loss: 2.6546\n",
      "Epoch 136/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3961 - loss: 2.3519 - val_accuracy: 0.3816 - val_loss: 2.6650\n",
      "Epoch 137/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3980 - loss: 2.3355 - val_accuracy: 0.3841 - val_loss: 2.6586\n",
      "Epoch 138/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4029 - loss: 2.3253 - val_accuracy: 0.3812 - val_loss: 2.6521\n",
      "Epoch 139/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4002 - loss: 2.3327 - val_accuracy: 0.3845 - val_loss: 2.6615\n",
      "Epoch 140/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4107 - loss: 2.3278 - val_accuracy: 0.3784 - val_loss: 2.6635\n",
      "Epoch 141/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4084 - loss: 2.3278 - val_accuracy: 0.3861 - val_loss: 2.6623\n",
      "Epoch 142/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4015 - loss: 2.3371 - val_accuracy: 0.3859 - val_loss: 2.6604\n",
      "Epoch 143/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4152 - loss: 2.3053 - val_accuracy: 0.3831 - val_loss: 2.6630\n",
      "Epoch 144/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4083 - loss: 2.2849 - val_accuracy: 0.3890 - val_loss: 2.6582\n",
      "Epoch 145/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4008 - loss: 2.3270 - val_accuracy: 0.3888 - val_loss: 2.6547\n",
      "Epoch 146/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4047 - loss: 2.3165 - val_accuracy: 0.3810 - val_loss: 2.6585\n",
      "Epoch 147/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4103 - loss: 2.3108 - val_accuracy: 0.3900 - val_loss: 2.6532\n",
      "Epoch 148/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4118 - loss: 2.2908 - val_accuracy: 0.3870 - val_loss: 2.6463\n",
      "Epoch 149/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4106 - loss: 2.2829 - val_accuracy: 0.3882 - val_loss: 2.6662\n",
      "Epoch 150/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4115 - loss: 2.2949 - val_accuracy: 0.3890 - val_loss: 2.6541\n",
      "Epoch 151/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4088 - loss: 2.3029 - val_accuracy: 0.3757 - val_loss: 2.6655\n",
      "Epoch 152/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4161 - loss: 2.3067 - val_accuracy: 0.3808 - val_loss: 2.6691\n",
      "Epoch 153/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4081 - loss: 2.2973 - val_accuracy: 0.3839 - val_loss: 2.6566\n",
      "Epoch 154/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4093 - loss: 2.2980 - val_accuracy: 0.3874 - val_loss: 2.6579\n",
      "Epoch 155/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4194 - loss: 2.2798 - val_accuracy: 0.3966 - val_loss: 2.6543\n",
      "Epoch 156/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4136 - loss: 2.2870 - val_accuracy: 0.3878 - val_loss: 2.6463\n",
      "Epoch 157/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4184 - loss: 2.2684 - val_accuracy: 0.3859 - val_loss: 2.6608\n",
      "Epoch 158/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4147 - loss: 2.2982 - val_accuracy: 0.3874 - val_loss: 2.6660\n",
      "Epoch 159/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4045 - loss: 2.3147 - val_accuracy: 0.3882 - val_loss: 2.6616\n",
      "Epoch 160/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4200 - loss: 2.2619 - val_accuracy: 0.3861 - val_loss: 2.6651\n",
      "Epoch 161/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4181 - loss: 2.2889 - val_accuracy: 0.3884 - val_loss: 2.6609\n",
      "Epoch 162/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4153 - loss: 2.2650 - val_accuracy: 0.3751 - val_loss: 2.6616\n",
      "Epoch 163/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4193 - loss: 2.2712 - val_accuracy: 0.3876 - val_loss: 2.6690\n",
      "Epoch 164/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4143 - loss: 2.2771 - val_accuracy: 0.3884 - val_loss: 2.6682\n",
      "Epoch 165/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4164 - loss: 2.2543 - val_accuracy: 0.3876 - val_loss: 2.6647\n",
      "Epoch 166/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4185 - loss: 2.2879 - val_accuracy: 0.3853 - val_loss: 2.6700\n",
      "Epoch 167/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4225 - loss: 2.2465 - val_accuracy: 0.3831 - val_loss: 2.6641\n",
      "Epoch 168/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4180 - loss: 2.2523 - val_accuracy: 0.3853 - val_loss: 2.6574\n",
      "Epoch 169/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4214 - loss: 2.2421 - val_accuracy: 0.3861 - val_loss: 2.6687\n",
      "Epoch 170/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4099 - loss: 2.2942 - val_accuracy: 0.3839 - val_loss: 2.6586\n",
      "Epoch 171/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4254 - loss: 2.2618 - val_accuracy: 0.3890 - val_loss: 2.6586\n",
      "Epoch 172/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4198 - loss: 2.2538 - val_accuracy: 0.3892 - val_loss: 2.6637\n",
      "Epoch 173/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4231 - loss: 2.2467 - val_accuracy: 0.3894 - val_loss: 2.6630\n",
      "Epoch 174/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4258 - loss: 2.2521 - val_accuracy: 0.3908 - val_loss: 2.6617\n",
      "Epoch 175/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4248 - loss: 2.2528 - val_accuracy: 0.3884 - val_loss: 2.6610\n",
      "Epoch 176/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4175 - loss: 2.2683 - val_accuracy: 0.3876 - val_loss: 2.6659\n",
      "Epoch 177/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4275 - loss: 2.2372 - val_accuracy: 0.3884 - val_loss: 2.6602\n",
      "Epoch 178/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4254 - loss: 2.2444 - val_accuracy: 0.3845 - val_loss: 2.6627\n",
      "Epoch 179/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4238 - loss: 2.2599 - val_accuracy: 0.3876 - val_loss: 2.6695\n",
      "Epoch 180/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4262 - loss: 2.2485 - val_accuracy: 0.3870 - val_loss: 2.6649\n",
      "Epoch 181/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4294 - loss: 2.2329 - val_accuracy: 0.3908 - val_loss: 2.6658\n",
      "Epoch 182/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4220 - loss: 2.2552 - val_accuracy: 0.3876 - val_loss: 2.6644\n",
      "Epoch 183/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4254 - loss: 2.2371 - val_accuracy: 0.3923 - val_loss: 2.6703\n",
      "Epoch 184/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4273 - loss: 2.2203 - val_accuracy: 0.3863 - val_loss: 2.6701\n",
      "Epoch 185/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4230 - loss: 2.2543 - val_accuracy: 0.3876 - val_loss: 2.6720\n",
      "Epoch 186/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4216 - loss: 2.2280 - val_accuracy: 0.3880 - val_loss: 2.6661\n",
      "Epoch 187/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4294 - loss: 2.2229 - val_accuracy: 0.3931 - val_loss: 2.6530\n",
      "Epoch 188/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4274 - loss: 2.2339 - val_accuracy: 0.3849 - val_loss: 2.6692\n",
      "Epoch 189/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4235 - loss: 2.2161 - val_accuracy: 0.3845 - val_loss: 2.6803\n",
      "Epoch 190/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4246 - loss: 2.2295 - val_accuracy: 0.3857 - val_loss: 2.6688\n",
      "Epoch 191/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4310 - loss: 2.2200 - val_accuracy: 0.3898 - val_loss: 2.6649\n",
      "Epoch 192/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4303 - loss: 2.2101 - val_accuracy: 0.3870 - val_loss: 2.6628\n",
      "Epoch 193/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4285 - loss: 2.2319 - val_accuracy: 0.3910 - val_loss: 2.6648\n",
      "Epoch 194/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4316 - loss: 2.2231 - val_accuracy: 0.3894 - val_loss: 2.6603\n",
      "Epoch 195/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4286 - loss: 2.2248 - val_accuracy: 0.3853 - val_loss: 2.6652\n",
      "Epoch 196/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4385 - loss: 2.1879 - val_accuracy: 0.3923 - val_loss: 2.6633\n",
      "Epoch 197/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4343 - loss: 2.1908 - val_accuracy: 0.3915 - val_loss: 2.6545\n",
      "Epoch 198/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4306 - loss: 2.2011 - val_accuracy: 0.3923 - val_loss: 2.6580\n",
      "Epoch 199/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4217 - loss: 2.2256 - val_accuracy: 0.3868 - val_loss: 2.6687\n",
      "Epoch 200/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4299 - loss: 2.2046 - val_accuracy: 0.3880 - val_loss: 2.6558\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.3829 - loss: 2.7095\n",
      "Test Accuracy: 0.3880\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X.shape, y.shape)\n",
    "# Define the neural network model\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(256, input_shape=(input_shape,), activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model = create_model(X_train.shape[1])\n",
    "# model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=256, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/26_05_2024_14-17/bird_species_classifier_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for each class\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step\n",
      "[[6.77345997e-06 3.61297367e-04 9.99722444e-03 ... 4.80583822e-06\n",
      "  1.78343207e-13 2.68834672e-04]\n",
      " [4.24841885e-03 2.23327857e-02 1.57664064e-04 ... 7.53935456e-05\n",
      "  5.43763292e-07 4.25365070e-05]\n",
      " [1.19067394e-04 5.29814046e-04 1.08128644e-08 ... 4.94190090e-07\n",
      "  5.58729380e-06 6.24294003e-08]\n",
      " ...\n",
      " [4.08890657e-03 6.24113530e-03 3.37525353e-06 ... 3.06950795e-07\n",
      "  3.32492964e-05 3.94365750e-04]\n",
      " [1.92772562e-03 6.30501006e-03 4.82090429e-04 ... 7.24603655e-04\n",
      "  5.35062514e-04 5.27585275e-04]\n",
      " [3.43275652e-03 1.14992205e-02 1.04471333e-02 ... 2.62938003e-04\n",
      "  2.07573539e-05 6.70732604e-03]]\n",
      "[ 20 143 100 ...  81  41   9]\n",
      "[ 85 143 100 ...  81  41  82]\n",
      "[False  True  True ...  True  True False]\n",
      "0.31643499591169255\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "print(np.argmax(predictions, axis=1))\n",
    "print(np.argmax(y_test, axis=1))\n",
    "print(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unlabeled_data(file_paths, max_length=22050*5, batch_size=10):\n",
    "    X = []\n",
    "\n",
    "    # Split the data into batches\n",
    "    batches = [file_paths[i:i + batch_size] for i in range(0, len(file_paths), batch_size)]\n",
    "\n",
    "    # Process batches in parallel using ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_batch_unlabeled, batch_files, max_length) for batch_files in batches]\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            X_batch = future.result()\n",
    "            X.extend(X_batch)\n",
    "\n",
    "    return np.array(X)\n",
    "\n",
    "def process_batch_unlabeled(file_paths, max_length):\n",
    "    X_batch = []\n",
    "    for file_path in file_paths:\n",
    "        formatted_features = extract_and_format_features(file_path, max_length)\n",
    "        if formatted_features is not None:\n",
    "            X_batch.append(formatted_features)\n",
    "    return X_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610f885ed5ac4cb2bf8e1f610f32f7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.21212883e+01 -2.87777729e+01 -3.02512302e+01 ...  2.24155467e-03\n",
      "   2.17884989e-03  1.60560049e-02]\n",
      " [-2.36302452e+01 -2.00415802e+01 -2.05173740e+01 ...  1.29544584e-03\n",
      "   6.01685420e-03  1.10199349e-02]\n",
      " [-1.94876842e+01 -1.36277876e+01 -1.23970518e+01 ...  7.98544555e-04\n",
      "   1.37835192e-02  2.12538913e-02]\n",
      " ...\n",
      " [-1.60226192e+01 -9.08266449e+00 -1.18834248e+01 ...  5.80647145e-04\n",
      "   3.04474146e-03  6.13697013e-03]\n",
      " [-2.33688107e+01 -1.95451126e+01 -1.99254322e+01 ...  7.61987932e-04\n",
      "   1.41835643e-03  5.15813008e-03]\n",
      " [-4.09209938e+01 -3.70874748e+01 -3.48483086e+01 ...  1.53483571e-02\n",
      "   1.25856474e-02  8.58121291e-02]]\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_unlabeled)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Standardize the features\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m X_unlabeled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:1040\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m        Transformed array.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m     copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m   1043\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1044\u001b[0m         X,\n\u001b[0;32m   1045\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1050\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1632\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Load the scaler you fitted earlier\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Assuming the scaler was saved previously:\n",
    "# scaler = joblib.load('scaler.pkl')  # Uncomment if you have saved the scaler\n",
    "\n",
    "\n",
    "\n",
    "# Load the unlabeled data from './birdclef-2024/unlabeled_soundscapes/'\n",
    "\n",
    "unlabeled_file_paths = ['./birdclef-2024/unlabeled_soundscapes/' + file for file in os.listdir('./birdclef-2024/unlabeled_soundscapes/')]\n",
    "\n",
    "\n",
    "\n",
    "X_unlabeled = load_unlabeled_data(unlabeled_file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8444, 684)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_unlabeled.shape)\n",
    "# Standardize the features\n",
    "X_unlabeled = scaler.transform(X_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.21476203e+01 -2.88147565e+01 -3.03063772e+01 ...  6.98346394e-03\n",
      "   7.17909965e-03  2.09998116e-02]\n",
      " [-2.36496142e+01 -2.00677206e+01 -2.05555130e+01 ...  6.03257134e-03\n",
      "   1.10998611e-02  1.59468060e-02]\n",
      " [-1.95036562e+01 -1.36459674e+01 -1.24210021e+01 ...  5.53315760e-03\n",
      "   1.90339952e-02  2.62151778e-02]\n",
      " ...\n",
      " [-1.60357498e+01 -9.09520304e+00 -1.19064776e+01 ...  5.31415845e-03\n",
      "   8.06366206e-03  1.10474206e-02]\n",
      " [-2.33879653e+01 -1.95706369e+01 -1.99625369e+01 ...  5.49641614e-03\n",
      "   6.40220802e-03  1.00652888e-02]\n",
      " [-4.09545418e+01 -3.71347721e+01 -3.49114880e+01 ...  2.01565377e-02\n",
      "   1.78102943e-02  9.09905157e-02]]\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step\n"
     ]
    }
   ],
   "source": [
    "print(X_unlabeled)\n",
    "\n",
    "predictions = model.predict(X_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  row_id  asbfly  ashdro1  ashpri1  ashwoo2       asikoe2  \\\n",
      "0  soundscape_1000170626     0.0      0.0      0.0      0.0  0.000000e+00   \n",
      "1  soundscape_1000308629     0.0      0.0      0.0      0.0  4.282066e-37   \n",
      "2  soundscape_1000389428     0.0      0.0      0.0      0.0  0.000000e+00   \n",
      "3  soundscape_1000424265     0.0      0.0      0.0      0.0  0.000000e+00   \n",
      "4  soundscape_1000450112     0.0      0.0      0.0      0.0  0.000000e+00   \n",
      "\n",
      "   asiope1  aspfly1  aspswi1  barfly1  ...  whbwoo2  whcbar1  whiter2  whrmun  \\\n",
      "0      0.0      0.0      0.0      0.0  ...      0.0      0.0      0.0     0.0   \n",
      "1      0.0      0.0      0.0      0.0  ...      0.0      0.0      0.0     0.0   \n",
      "2      0.0      0.0      0.0      0.0  ...      0.0      0.0      0.0     0.0   \n",
      "3      0.0      0.0      0.0      0.0  ...      0.0      0.0      0.0     0.0   \n",
      "4      0.0      0.0      0.0      0.0  ...      0.0      0.0      0.0     0.0   \n",
      "\n",
      "   whtkin2  woosan  wynlau1       yebbab1  yebbul3  zitcis1  \n",
      "0      0.0     0.0      0.0  0.000000e+00      0.0      0.0  \n",
      "1      0.0     0.0      0.0  0.000000e+00      0.0      0.0  \n",
      "2      0.0     0.0      0.0  0.000000e+00      0.0      0.0  \n",
      "3      0.0     0.0      0.0  7.806537e-24      0.0      0.0  \n",
      "4      0.0     0.0      0.0  0.000000e+00      0.0      0.0  \n",
      "\n",
      "[5 rows x 183 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate row IDs based on the filenames (remove path and extension)\n",
    "row_ids = [os.path.splitext(os.path.basename(file_path))[0] for file_path in unlabeled_file_paths]\n",
    "\n",
    "# Ensure the number of row_ids matches the number of predictions\n",
    "assert len(row_ids) == predictions.shape[0], \"Number of row_ids must match the number of predictions\"\n",
    "\n",
    "# Prepare the column names\n",
    "species_columns = df_train['primary_label'].astype('category').cat.categories.tolist()\n",
    "columns = ['row_id'] + species_columns\n",
    "\n",
    "# Combine row_ids with predictions\n",
    "results = []\n",
    "for row_id, probs in zip(row_ids, predictions):\n",
    "    results.append([row_id] + probs.tolist())\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_predictions = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Save predictions to CSV\n",
    "df_predictions.to_csv('predictions.csv', index=False)\n",
    "df_predictions[\"row_id\"]  = df_predictions[\"row_id\"].apply(lambda x: \"soundscape_\" + x)\n",
    "print(df_predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = pd.read_csv('X.csv', header=None)\n",
    "y_2 = pd.read_csv('y.csv', header=None)\n",
    "\n",
    "X_2 = X_2.to_numpy()\n",
    "y_2 = y_2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_spectrogram(audio, sr=22050, n_mels=128, fmax=8000):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import Maxpooling2D and Conv2D, concatenate, model, input\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(256, input_shape=(input_shape,), activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_cnn_model(input_shape=(128, 128, 1), num_meta_features=2, num_classes=10):\n",
    "    # Image input branch\n",
    "    img_input = Input(shape=input_shape, name='img_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Metadata input branch\n",
    "    meta_input = Input(shape=(num_meta_features,), name='meta_input')\n",
    "    y = Dense(256, activation='relu')(meta_input)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(128, activation='relu')(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(64, activation='relu')(y)\n",
    "    \n",
    "    # Concatenate the outputs of the image and metadata branches\n",
    "    combined = concatenate([x, y])\n",
    "    z = Dense(256, activation='relu')(combined)\n",
    "    z = Dense(num_classes, activation='softmax')(z)\n",
    "    \n",
    "    model = Model(inputs=[img_input, meta_input], outputs=z)\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ img_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ img_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meta_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ meta_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25152</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,439,168</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,774</span> │ dense_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ img_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m,  │        \u001b[38;5;34m320\u001b[0m │ img_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meta_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m768\u001b[0m │ meta_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_5[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_70 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25152\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m6,439,168\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_72 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m)       │     \u001b[38;5;34m46,774\u001b[0m │ dense_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,620,534</span> (25.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,620,534\u001b[0m (25.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,620,534</span> (25.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,620,534\u001b[0m (25.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cnn = build_cnn_model(input_shape=(128, 128, 1), num_meta_features=2, num_classes=df_train['primary_label'].nunique())\n",
    "model_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24459 files.\n",
      "(24459, 684)\n",
      "(24459, 1)\n",
      "(24459, 684) (24459, 182)\n",
      "Epoch 1/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 528ms/step - accuracy: 0.0388 - loss: 4.5253 - val_accuracy: 0.0000e+00 - val_loss: 8.0123\n",
      "Epoch 2/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 521ms/step - accuracy: 0.1314 - loss: 3.6763 - val_accuracy: 0.0070 - val_loss: 9.7762\n",
      "Epoch 3/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 527ms/step - accuracy: 0.1761 - loss: 3.4023 - val_accuracy: 0.0090 - val_loss: 10.9418\n",
      "Epoch 4/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 550ms/step - accuracy: 0.1999 - loss: 3.2561 - val_accuracy: 0.0055 - val_loss: 11.5770\n",
      "Epoch 5/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 620ms/step - accuracy: 0.2158 - loss: 3.1728 - val_accuracy: 0.0080 - val_loss: 12.1268\n",
      "Epoch 6/200\n",
      "\u001b[1m39/77\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 599ms/step - accuracy: 0.2369 - loss: 3.0620"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load X and y from CSV files\n",
    "X = pd.read_csv('X.csv', header=None).values\n",
    "y = pd.read_csv('y.csv', header=None).values\n",
    "\n",
    "print(f\"Loaded {X.shape[0]} files.\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Define the CNN model with metadata input\n",
    "def build_cnn_model(input_shape=(128, 128, 1), num_meta_features=2, num_classes=10):\n",
    "    # Image input branch\n",
    "    img_input = Input(shape=input_shape, name='img_input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Metadata input branch\n",
    "    meta_input = Input(shape=(num_meta_features,), name='meta_input')\n",
    "    y = Dense(256, activation='relu')(meta_input)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(128, activation='relu')(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(64, activation='relu')(y)\n",
    "    \n",
    "    # Concatenate the outputs of the image and metadata branches\n",
    "    combined = concatenate([x, y])\n",
    "    z = Dense(256, activation='relu')(combined)\n",
    "    z = Dense(num_classes, activation='softmax')(z)\n",
    "    \n",
    "    model = Model(inputs=[img_input, meta_input], outputs=z)\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Assuming you have the spectrograms stored as a 4D numpy array with shape (num_samples, 128, 128, 1)\n",
    "# If you have the spectrograms in another format, you need to load or preprocess them accordingly.\n",
    "\n",
    "# Example usage\n",
    "# Let's assume you have the spectrograms stored in an array called `spectrograms`\n",
    "# For demonstration, we'll create dummy spectrogram data\n",
    "# spectrograms = np.random.rand(X.shape[0], 128, 128, 1)  # Dummy data, replace with actual spectrograms\n",
    "\n",
    "# Dummy data for demonstration\n",
    "spectrograms = np.random.rand(X.shape[0], 128, 128, 1)\n",
    "\n",
    "# Number of metadata features\n",
    "num_meta_features = X.shape[1]\n",
    "\n",
    "# Number of classes\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "# Build the model\n",
    "model = build_cnn_model(input_shape=(128, 128, 1), num_meta_features=num_meta_features, num_classes=num_classes)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    {'img_input': spectrograms, 'meta_input': X},\n",
    "    y,\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate({'img_input': spectrograms, 'meta_input': X_test}, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
